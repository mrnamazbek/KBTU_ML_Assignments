# –ú–æ–¥—É–ª—å 7: Computer Vision (–°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏)

> **–ó–∞—á–µ–º —ç—Ç–æ—Ç –º–æ–¥—É–ª—å?**  
> Computer Vision (CV) ‚Äî —ç—Ç–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –º–∞—à–∏–Ω–∞–º "–≤–∏–¥–µ—Ç—å" –∏ –ø–æ–Ω–∏–º–∞—Ç—å –≤–∏–∑—É–∞–ª—å–Ω—ã–π –º–∏—Ä.
> - **–ë–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ**: CNN –∏–º–∏—Ç–∏—Ä—É—é—Ç —Ä–∞–±–æ—Ç—É –∑—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ—Ä—ã –º–æ–∑–≥–∞, –≥–¥–µ —Ä–∞–∑–Ω—ã–µ –≥—Ä—É–ø–ø—ã –Ω–µ–π—Ä–æ–Ω–æ–≤ –æ—Ç–≤–µ—á–∞—é—Ç –∑–∞ —Ä–∞–∑–Ω—ã–µ —á–µ—Ä—Ç—ã (–ª–∏–Ω–∏–∏, —Ñ–æ—Ä–º—ã, –æ–±—ä–µ–∫—Ç—ã).
> - **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å**: –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç –æ–±—ã—á–Ω—ã—Ö —Å–µ—Ç–µ–π, CNN —É—á–∏—Ç—ã–≤–∞—é—Ç, —á—Ç–æ —Å–æ—Å–µ–¥–Ω–∏–µ –ø–∏–∫—Å–µ–ª–∏ —Å–≤—è–∑–∞–Ω—ã –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –æ–≥—Ä–æ–º–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –º–∏–Ω–∏–º—É–º–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
> - **–í–µ–∑–¥–µ—Å—É—â–Ω–æ—Å—Ç—å**: –æ—Ç FaceID –≤ –≤–∞—à–µ–º —Ç–µ–ª–µ—Ñ–æ–Ω–µ –¥–æ –∞–≤—Ç–æ–ø–∏–ª–æ—Ç–∞ Tesla ‚Äî –º–æ–¥—É–ª–∏ CV —Å–µ–π—á–∞—Å –ø–æ–≤—Å—é–¥—É.

---

## 7.1 –°–≤–µ—Ä—Ç–∫–∞ (Convolution)

### 1) –ò–Ω—Ç—É–∏—Ü–∏—è –∏ —Å—É—Ç—å

**–ü—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ (ELI5):**  
–ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ —É —Ç–µ–±—è –µ—Å—Ç—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è, –∏ —Ç—ã –ø—Ä–æ–≤–æ–¥–∏—à—å –ø–æ –Ω–µ–π –º–∞–ª–µ–Ω—å–∫–æ–π –ª—É–ø–æ–π (—Ñ–∏–ª—å—Ç—Ä–æ–º 3√ó3). –í –∫–∞–∂–¥–æ–π –ø–æ–∑–∏—Ü–∏–∏ –ª—É–ø–∞ –∏—â–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—É—é –ª–∏–Ω–∏—é, —É–≥–æ–ª, —Ç–µ–∫—Å—Ç—É—Ä—É). –†–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî –∫–∞—Ä—Ç–∞, –≥–¥–µ –∑–∞–ø–∏—Å–∞–Ω–æ "–Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω –≤–∏–¥–µ–Ω –≤ –∫–∞–∂–¥–æ–º –º–µ—Å—Ç–µ".

**–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏:**  
–°–≤–µ—Ä—Ç–∫–∞ (convolution) ‚Äî —ç—Ç–æ –æ–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è **—Ñ–∏–ª—å—Ç—Ä–∞ (kernel)** –∫ –≤—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, —Å–∫–æ–ª—å–∑—è –ø–æ –Ω–µ–º—É —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º —à–∞–≥–æ–º (stride) –∏ –≤—ã—á–∏—Å–ª—è—è –≤–∑–≤–µ—à–µ–Ω–Ω—É—é —Å—É–º–º—É –ø–∏–∫—Å–µ–ª–µ–π. –†–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî **feature map**, –ø–æ–∫–∞–∑—ã–≤–∞—é—â–∞—è –Ω–∞–ª–∏—á–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –≤ —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç—è—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.

**–§–∏–∑–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª:**  
–§–∏–ª—å—Ç—Ä = **–¥–µ—Ç–µ–∫—Ç–æ—Ä –ø–∞—Ç—Ç–µ—Ä–Ω–∞**. –°–≤–µ—Ä—Ç–æ—á–Ω–∞—è —Å–µ—Ç—å —É—á–∏—Ç—Å—è –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º –¥–ª—è –∑–∞–¥–∞—á–∏.

### 2) –ó–∞—á–µ–º –∏ –∫–æ–≥–¥–∞ (Business Value)

**–ö–∞–∫—É—é –ø—Ä–æ–±–ª–µ–º—É —Ä–µ—à–∞–µ—Ç:**
- **–õ–æ–∫–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã**: –∫—Ä–∞–π, —É–≥–æ–ª, —Ç–µ–∫—Å—Ç—É—Ä–∞ (–Ω–µ –Ω—É–∂–Ω–æ —Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ä–∞–∑—É)
- **Translation Invariance**: –ø–∞—Ç—Ç–µ—Ä–Ω —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç—Å—è –≤ –ª—é–±–æ–π —á–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- **Parameter Sharing**: –æ–¥–∏–Ω —Ñ–∏–ª—å—Ç—Ä –Ω–∞ –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ‚Üí –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —á–µ–º fully connected

**–ì–¥–µ —ç—Ç–æ –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç:**
- **Computer Vision**: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (ImageNet), –æ–±—ä–µ–∫—Ç–æ–≤ detection (YOLO), —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
- **–ú–µ–¥–∏—Ü–∏–Ω–∞**: –∞–Ω–∞–ª–∏–∑ —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≤—Å–∫–∏—Ö —Å–Ω–∏–º–∫–æ–≤, –ú–†–¢
- **–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ –∞–≤—Ç–æ**: —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤, –¥–æ—Ä–æ–∂–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤
- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å**: —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ª–∏—Ü

### 3) –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —è–¥—Ä–æ

**2D Convolution:**

–í—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: **I** (H √ó W)  
–§–∏–ª—å—Ç—Ä (kernel): **K** (k √ó k), –æ–±—ã—á–Ω–æ k = 3 –∏–ª–∏ 5

**–û–ø–µ—Ä–∞—Ü–∏—è 2D —Å–≤–µ—Ä—Ç–∫–∏:**
–î–ª—è –≤—Ö–æ–¥–∞ $I$ –∏ —Ñ–∏–ª—å—Ç—Ä–∞ $K$ —Ä–∞–∑–º–µ—Ä–∞ $k \times k$:
$$
(I * K)[i, j] = \sum_{m=0}^{k-1} \sum_{n=0}^{k-1} I[i+m, j+n] \cdot K[m, n]
$$

**–†–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–Ω–æ–π feature map:**
$$
H_{out} = \left\lfloor \frac{H_{in} - K + 2P}{S} \right\rfloor + 1
$$
–≥–¥–µ:
- $H_{in}$ ‚Äî –≤—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä
- $K$ ‚Äî —Ä–∞–∑–º–µ—Ä —è–¥—Ä–∞ (kernel)
- $P$ ‚Äî –æ—Ç—Å—Ç—É–ø (padding)
- $S$ ‚Äî —à–∞–≥ (stride)

> [!CAUTION]
> **Production Warning: RGB vs BGR**  
> –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ `OpenCV` –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —á–∏—Ç–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ **BGR**, –∞ `Matplotlib` –∏ `PyTorch` –æ–∂–∏–¥–∞—é—Ç **RGB**. –ï—Å–ª–∏ –≤–∞—à–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –≤–¥—Ä—É–≥ –Ω–∞—á–∞–ª–∞ "—Ç—É–ø–∏—Ç—å" –Ω–∞ —Ç–µ—Å—Ç–∞—Ö, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, –Ω–µ –ø–µ—Ä–µ–ø—É—Ç–∞–ª–∏ –ª–∏ –≤—ã –ø–æ—Ä—è–¥–æ–∫ —Ü–≤–µ—Ç–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤. –°–∏–Ω–µ–µ –ª–∏—Ü–æ —á–µ–ª–æ–≤–µ–∫–∞ ‚Äî –ø–µ—Ä–≤—ã–π –ø—Ä–∏–∑–Ω–∞–∫ —ç—Ç–æ–π –æ—à–∏–±–∫–∏!

> [!TIP]
> **–ê–Ω–∞–ª–æ–≥–∏—è: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ–Ω–∞—Ä–∏–∫–æ–º**  
> –ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ, —á—Ç–æ –≤—ã –≤ —Ç–µ–º–Ω–æ–π –∫–æ–º–Ω–∞—Ç–µ —Å —Ñ–æ–Ω–∞—Ä–∏–∫–æ–º, –Ω–∞ —Å—Ç–µ–∫–ª–æ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∞–∫–ª–µ–µ–Ω —Ç—Ä–∞—Ñ–∞—Ä–µ—Ç –≤ —Ñ–æ—Ä–º–µ –±—É–∫–≤—ã "–•". –í—ã –≤–æ–¥–∏—Ç–µ —Ñ–æ–Ω–∞—Ä–∏–∫–æ–º –ø–æ —Å—Ç–µ–Ω–µ. –¢–∞–º, –≥–¥–µ –Ω–∞ —Å—Ç–µ–Ω–µ –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–∞ –±—É–∫–≤–∞ "–•", —Å–≤–µ—Ç –ø—Ä–æ–π–¥–µ—Ç –∏–¥–µ–∞–ª—å–Ω–æ –∏ –¥–∞—Å—Ç —è—Ä–∫–æ–µ –ø—è—Ç–Ω–æ. –í –¥—Ä—É–≥–∏—Ö –º–µ—Å—Ç–∞—Ö –ø—è—Ç–Ω–æ –±—É–¥–µ—Ç —Ç—É—Å–∫–ª—ã–º. Feature Map ‚Äî —ç—Ç–æ –∫–∞—Ä—Ç–∞ —è—Ä–∫–æ—Å—Ç–∏ —ç—Ç–∏—Ö –ø—è—Ç–µ–Ω.

**Channels (–∫–∞–Ω–∞–ª—ã):**

**–¶–≤–µ—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:** 3 –∫–∞–Ω–∞–ª–∞ (RGB)  
**–§–∏–ª—å—Ç—Ä:** —Ç–æ–∂–µ 3 –∫–∞–Ω–∞–ª–∞ (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ –∫–∞–∂–¥—ã–π —Ü–≤–µ—Ç)  
**–°–≤–µ—Ä—Ç–∫–∞:** —Å—É–º–º–∏—Ä—É–µ–º –ø–æ –≤—Å–µ–º –∫–∞–Ω–∞–ª–∞–º:
$$
\text{Output}[i, j] = \sum_{c=0}^{C_{in}-1} \sum_{m=0}^{k-1} \sum_{n=0}^{k-1} I[i+m, j+n, c] \cdot K[m, n, c]
$$


**–ú–Ω–æ–∂–µ—Å—Ç–≤–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤:**  
–û–¥–∏–Ω —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π –æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç **N —Ñ–∏–ª—å—Ç—Ä–æ–≤** ‚Üí **N feature maps**.

**Output:** (H_out, W_out, N)

### 4) Middle-level –Ω—é–∞–Ω—Å—ã

**–ü—Ä–æ–±–ª–µ–º–∞ 1: –ó–∞—á–µ–º —Å–≤–µ—Ä—Ç–∫–∞, –∞ –Ω–µ Fully Connected?**

**Fully Connected –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è 224√ó224√ó3:**
```
–ß–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ = 224¬∑224¬∑3 ¬∑ N_hidden ‚âà 150,000 ¬∑ N_hidden
```

–ü—Ä–∏ N_hidden = 1000 ‚Üí 150 –º–ª–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç–æ–ª—å–∫–æ –≤ –ø–µ—Ä–≤–æ–º —Å–ª–æ–µ!

**–°–≤–µ—Ä—Ç–∫–∞ (—Ñ–∏–ª—å—Ç—Ä 3√ó3√ó3, 64 —Ñ–∏–ª—å—Ç—Ä–∞):**
```
–ß–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ = 3¬∑3¬∑3¬∑64 = 1,728
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Å–≤–µ—Ä—Ç–∫–∏:**
- ‚úÖ **Parameter Sharing**: –æ–¥–∏–Ω —Ñ–∏–ª—å—Ç—Ä –Ω–∞ –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
- ‚úÖ **Sparse Connectivity**: –Ω–µ–π—Ä–æ–Ω —Å–º–æ—Ç—Ä–∏—Ç —Ç–æ–ª—å–∫–æ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é –æ–±–ª–∞—Å—Ç—å (receptive field)
- ‚úÖ **Translation Invariance**: –ø–∞—Ç—Ç–µ—Ä–Ω —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç—Å—è –≤–µ–∑–¥–µ

**–ü—Ä–æ–±–ª–µ–º–∞ 2: Receptive Field (—Ä–µ—Ü–µ–ø—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ)**

**Receptive field** ‚Äî —ç—Ç–æ –æ–±–ª–∞—Å—Ç—å –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è –≤–ª–∏—è–µ—Ç –Ω–∞ –¥–∞–Ω–Ω—ã–π –Ω–µ–π—Ä–æ–Ω.

**–û–¥–∏–Ω —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π —Å–ª–æ–π (3√ó3):**  
Receptive field = 3√ó3

**–î–≤–∞ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ—è (–∫–∞–∂–¥—ã–π 3√ó3):**
```
Layer 1: 3√ó3
Layer 2: –∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å layer 2 "–≤–∏–¥–∏—Ç" 3√ó3 –∏–∑ layer 1
‚Üí Receptive field –Ω–∞ –≤—Ö–æ–¥–µ = 5√ó5
```

**–ì–ª—É–±–æ–∫–∞—è —Å–µ—Ç—å:**  
Receptive field —Ä–∞—Å—Ç–µ—Ç —Å –≥–ª—É–±–∏–Ω–æ–π ‚Üí –≥–ª—É–±–æ–∫–∏–µ —Å–ª–æ–∏ "–≤–∏–¥—è—Ç" –±–æ–ª—å—à–∏–µ –æ–±–ª–∞—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.

**–ü—Ä–æ–±–ª–µ–º–∞ 3: –ß–∏—Å–ª–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–º —Å–ª–æ–µ**

**–§–æ—Ä–º—É–ª–∞:**
```
# –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ = k ¬∑ k ¬∑ C_in ¬∑ C_out + C_out
              |____________|   |_____|
               –≤–µ—Å–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤    biases
```

–≥–¥–µ:
- k ‚Äî —Ä–∞–∑–º–µ—Ä —Ñ–∏–ª—å—Ç—Ä–∞
- C_in ‚Äî —á–∏—Å–ª–æ –≤—Ö–æ–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
- C_out ‚Äî —á–∏—Å–ª–æ –≤—ã—Ö–æ–¥–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ (—Ñ–∏–ª—å—Ç—Ä–æ–≤)

**–ü—Ä–∏–º–µ—Ä:**
```
Input: 32√ó32√ó3
Conv layer: 64 —Ñ–∏–ª—å—Ç—Ä–æ–≤ 3√ó3
‚Üí –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: 3¬∑3¬∑3¬∑64 + 64 = 1,792
```

### 5) –°—Ä–∞–≤–Ω–µ–Ω–∏–µ Convolution vs Fully Connected

| –ê—Å–ø–µ–∫—Ç | Convolution | Fully Connected |
|--------|------------|-----------------|
| **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã** | ‚úÖ –ú–∞–ª–æ (parameter sharing) | ‚ùå –ú–Ω–æ–≥–æ |
| **Locality** | ‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ | ‚ùå –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å–≤—è–∑–∏ |
| **Translation Invariance** | ‚úÖ –î–∞ | ‚ùå –ù–µ—Ç |
| **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å** | –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ | –í–µ–∫—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ |

---

## 7.2 Pooling (–ü—É–ª–∏–Ω–≥)

### 1) –ò–Ω—Ç—É–∏—Ü–∏—è –∏ —Å—É—Ç—å

**–ü—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ (ELI5):**  
–ü–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ —Ñ–∏–ª—å—Ç—Ä –Ω–∞—à–µ–ª –ø–∞—Ç—Ç–µ—Ä–Ω –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–≥–ª–∞–∑ –∫–æ—Ç–∞ –≤–∏–¥–µ–Ω –∑–¥–µ—Å—å"), –Ω–∞–º –Ω–µ –Ω—É–∂–Ω—ã **—Ç–æ—á–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã** –ø–∏–∫—Å–µ–ª—è. –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∑–Ω–∞—Ç—å: "–≥–ª–∞–∑ –≥–¥–µ-—Ç–æ –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏". Pooling **—É–ø—Ä–æ—â–∞–µ—Ç** feature map, —Å–æ—Ö—Ä–∞–Ω—è—è –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –Ω–æ —É–º–µ–Ω—å—à–∞—è —Ä–∞–∑–º–µ—Ä.

**–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏:**  
Pooling ‚Äî —ç—Ç–æ –æ–ø–µ—Ä–∞—Ü–∏—è **downsampling** (—É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏) feature map –ø—É—Ç–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏–π –≤ –Ω–µ–±–æ–ª—å—à–∏—Ö –æ–∫–Ω–∞—Ö (–æ–±—ã—á–Ω–æ 2√ó2). –û—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–ª—å ‚Äî **—É–º–µ–Ω—å—à–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π** –∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ **–Ω–µ–±–æ–ª—å—à–æ–π translation invariance**.

### 2) –ó–∞—á–µ–º –∏ –∫–æ–≥–¥–∞ (Business Value)

**–ö–∞–∫—É—é –ø—Ä–æ–±–ª–µ–º—É —Ä–µ—à–∞–µ—Ç:**
- **–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å**: —É–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä feature maps ‚Üí –º–µ–Ω—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- **Overfitting**: —É–º–µ–Ω—å—à–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **Translation Invariance**: –º–∞–ª—ã–µ —Å–¥–≤–∏–≥–∏ –æ–±—ä–µ–∫—Ç–∞ –Ω–µ –º–µ–Ω—è—é—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç

### 3) –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —è–¥—Ä–æ

**Max Pooling:**
–í—ã–±–æ—Ä –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –æ–∫–Ω–µ. –ï—Å–ª–∏ –æ–∫–Ω–æ $2 \times 2$ –∏ stride 2, —Ä–∞–∑–º–µ—Ä —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è –≤ 2 —Ä–∞–∑–∞:
$$
y = \max_{i,j \in \text{window}} x_{i,j}
$$

**Batch Normalization (–¥–ª—è —Å–≤–µ—Ä—Ç–æ—á–Ω–æ–≥–æ —Å–ª–æ—è):**
–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–¥–µ—Ç –ø–æ –≤—Å–µ–º—É –±–∞—Ç—á—É –ò –ø–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–∞–ª–∞ –æ—Ç–¥–µ–ª—å–Ω–æ.
$$
\hat{x} = \frac{x - \mu_B}{\sqrt{\sigma^2_B + \epsilon}}, \quad y = \gamma \hat{x} + \beta
$$

> [!IMPORTANT]
> **Batch Size & Batch Norm**  
> –í CV –º–∞–ª–µ–Ω—å–∫–∏–µ –±–∞—Ç—á–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2-4 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è) —É–±–∏–≤–∞—é—Ç —Ç–æ—á–Ω–æ—Å—Ç—å Batch Norm, —Ç–∞–∫ –∫–∞–∫ –æ—Ü–µ–Ω–∫–∏ —Å—Ä–µ–¥–Ω–µ–≥–æ –∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è —Å–ª–∏—à–∫–æ–º —à—É–º–Ω—ã–º–∏. –í —Ç–∞–∫–∏—Ö —Å–ª—É—á–∞—è—Ö –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `Group Normalization` –∏–ª–∏ `Layer Normalization`.

> [!TIP]
> **–ê–Ω–∞–ª–æ–≥–∏—è: –ö–æ–Ω—Å–ø–µ–∫—Ç –ª–µ–∫—Ü–∏–∏**  
> Pooling ‚Äî —ç—Ç–æ –∫–∞–∫ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞. –í–∞–º –Ω–µ –Ω—É–∂–Ω–æ –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –ª–µ–∫—Ç–æ—Ä–∞ (–∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å). –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å –≥–ª–∞–≤–Ω—É—é –º—ã—Å–ª—å –∞–±–∑–∞—Ü–∞ (–º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –∞–∫—Ç–∏–≤–∞—Ü–∏—é –≤ –æ–±–ª–∞—Å—Ç–∏). –í—ã —Ç–µ—Ä—è–µ—Ç–µ –¥–µ—Ç–∞–ª–∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è, –Ω–æ —Å—É—Ç—å (–Ω–∞–ª–∏—á–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞) –æ—Å—Ç–∞–µ—Ç—Å—è.

### 4) Middle-level –Ω—é–∞–Ω—Å—ã

**–ü—Ä–æ–±–ª–µ–º–∞ 1: Max vs Average Pooling**

| –¢–∏–ø | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å | –≠—Ñ—Ñ–µ–∫—Ç |
|-----|-------------------|--------|
| **Max Pooling** | Default | –°–æ—Ö—Ä–∞–Ω—è–µ—Ç **—Å–∏–ª—å–Ω—ã–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏** (—è—Ä–∫–∏–µ features) |
| **Average Pooling** | –ö–æ–≥–¥–∞ –≤–∞–∂–Ω–∞ –æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è | –°–≥–ª–∞–∂–∏–≤–∞–µ—Ç, –º–µ–Ω—å—à–µ overfitting |
| **Global Average Pooling** | –í–º–µ—Å—Ç–æ FC –≤ –∫–æ–Ω—Ü–µ | –ú–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –º–µ–Ω—å—à–µ overfitting |

**–ü—Ä–æ–±–ª–µ–º–∞ 2: Pooling —É–±–∏–≤–∞–µ—Ç —Ç–æ—á–Ω—É—é –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—é**

**–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏–µ:** —Å–ª–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –∑–∞–¥–∞—á, –≥–¥–µ –Ω—É–∂–Ω—ã —Ç–æ—á–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (semantic segmentation).

**–†–µ—à–µ–Ω–∏–µ:**  
–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (U-Net, Feature Pyramid Networks) –∏—Å–ø–æ–ª—å–∑—É—é—Ç **skip connections** –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.

**–ü—Ä–æ–±–ª–µ–º–∞ 3: –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã**

**Strided Convolution:**  
–í–º–µ—Å—Ç–æ pooling –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–≤–µ—Ä—Ç–∫—É —Å stride = 2 ‚Üí —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –±–µ–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Å–ª–æ—è pooling.

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ:**  
–°–µ—Ç—å **—É—á–∏—Ç—Å—è** –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º—É downsampling (–∞ pooling ‚Äî —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è).

### 5) –°—Ä–∞–≤–Ω–µ–Ω–∏–µ

| –û–ø–µ—Ä–∞—Ü–∏—è | –†–∞–∑–º–µ—Ä | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã | –ò–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
|----------|--------|----------|---------------|-------------------|
| **Max Pooling** | –£–º–µ–Ω—å—à–∞–µ—Ç—Å—è | 0 | ‚úÖ –ù–µ–±–æ–ª—å—à–∞—è | –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è |
| **Average Pooling** | –£–º–µ–Ω—å—à–∞–µ—Ç—Å—è | 0 | ‚úÖ –ù–µ–±–æ–ª—å—à–∞—è | –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ |
| **Strided Conv** | –£–º–µ–Ω—å—à–∞–µ—Ç—Å—è | –ï—Å—Ç—å (—É—á–∞—Ç—Å—è) | ‚ö†Ô∏è –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –≤–µ—Å–æ–≤ | –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã |

---

## 7.3 Dropout

### 1) –ò–Ω—Ç—É–∏—Ü–∏—è –∏ —Å—É—Ç—å

**–ü—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ (ELI5):**  
–ü—Ä–µ–¥—Å—Ç–∞–≤—å –∫–æ–º–∞–Ω–¥—É, –≥–¥–µ –æ–¥–∏–Ω –∏–≥—Ä–æ–∫ –æ—á–µ–Ω—å —Å–∏–ª–µ–Ω, –∏ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –Ω–∞ –Ω–µ–≥–æ –ø–æ–ª–∞–≥–∞—é—Ç—Å—è. –ï—Å–ª–∏ –æ–Ω –∑–∞–±–æ–ª–µ–µ—Ç, –∫–æ–º–∞–Ω–¥–∞ –ø—Ä–æ–∏–≥—Ä–∞–µ—Ç. Dropout ‚Äî —ç—Ç–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞, –≥–¥–µ **—Å–ª—É—á–∞–π–Ω—ã–µ –∏–≥—Ä–æ–∫–∏ –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç –∫–∞–∂–¥—É—é –∏–≥—Ä—É**. –ö–æ–º–∞–Ω–¥–∞ —É—á–∏—Ç—Å—è —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –ª—é–±–æ–≥–æ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∏–≥—Ä–æ–∫–∞ ‚Üí –≤—Å–µ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è —Å–∏–ª—å–Ω–µ–µ, –∫–æ–º–∞–Ω–¥–∞ —Ä–æ–±–∞—Å—Ç–Ω–µ–µ.

**–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏:**  
Dropout ‚Äî —ç—Ç–æ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω–∞—è —Ç–µ—Ö–Ω–∏–∫–∞, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–π –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è **—Å–ª—É—á–∞–π–Ω–æ "–≤—ã–∫–ª—é—á–∞—é—Ç—Å—è"** (–æ–±–Ω—É–ª—è—é—Ç—Å—è) –Ω–µ–π—Ä–æ–Ω—ã —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é p. –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç **co-adaptation** (–≤–∑–∞–∏–º–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å) –Ω–µ–π—Ä–æ–Ω–æ–≤ –∏ —Å–Ω–∏–∂–∞–µ—Ç overfitting.

**–§–∏–∑–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª:**  
Dropout = **–Ω–µ—è–≤–Ω–æ–µ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ**: –∫–∞–∂–¥–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è –æ–±—É—á–∞–µ—Ç —Ä–∞–∑–Ω—É—é –ø–æ–¥—Å–µ—Ç—å ‚Üí —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Å–µ—Ç—å = —Å—Ä–µ–¥–Ω–µ–µ –ø–æ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–º—É —á–∏—Å–ª—É –ø–æ–¥—Å–µ—Ç–µ–π.

### 2) –ó–∞—á–µ–º –∏ –∫–æ–≥–¥–∞ (Business Value)

**–ö–∞–∫—É—é –ø—Ä–æ–±–ª–µ–º—É —Ä–µ—à–∞–µ—Ç:**
- **Overfitting**: –æ—Å–æ–±–µ–Ω–Ω–æ –≤ fully connected —Å–ª–æ—è—Ö
- **Co-adaptation**: –Ω–µ–π—Ä–æ–Ω—ã —É—á–∞—Ç—Å—è —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ

**–ì–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:**
- **Fully connected —Å–ª–æ–∏** –≤ –∫–æ–Ω—Ü–µ CNN
- **RNN, LSTM** (dropout –º–µ–∂–¥—É —Å–ª–æ—è–º–∏)
- ‚ùå –†–µ–¥–∫–æ –≤ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ—è—Ö (spatial dropout –≤–º–µ—Å—Ç–æ –æ–±—ã—á–Ω–æ–≥–æ)

### 3) –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —è–¥—Ä–æ

**Training (–æ–±—É—á–µ–Ω–∏–µ):**

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–µ–π—Ä–æ–Ω–∞ h_i:
1. –°—ç–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å r_i ‚àº Bernoulli(p)
2. –í—ã–∫–ª—é—á–∏—Ç—å –Ω–µ–π—Ä–æ–Ω:
   ```
   h_i = {h_i, –µ—Å–ª–∏ r_i = 0 (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å 1-p);
          0,   –µ—Å–ª–∏ r_i = 1 (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å p)}
   ```

**–°—Ä–µ–¥–Ω–µ–µ:**  
E[h_i] = (1 - p) ¬∑ h_i

**Inference (—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ):**

**–í–∞—Ä–∏–∞–Ω—Ç 1 (scaling at test):**  
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ –Ω–µ–π—Ä–æ–Ω—ã, –Ω–æ —É–º–Ω–æ–∂–∏—Ç—å –Ω–∞ (1 - p):
```
h_i = (1 - p) ¬∑ h_i
```

**–í–∞—Ä–∏–∞–Ω—Ç 2 (inverted dropout, —Å—Ç–∞–Ω–¥–∞—Ä—Ç –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞—Ö):**  
–í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è —Å—Ä–∞–∑—É –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å:
```
h_i = h_i / (1 - p)  (–ø—Ä–∏ r_i = 0)
```
–¢–æ–≥–¥–∞ –ø—Ä–∏ inference –Ω–∏—á–µ–≥–æ –Ω–µ –º–µ–Ω—è–µ–º.

### 4) Middle-level –Ω—é–∞–Ω—Å—ã

**–ü—Ä–æ–±–ª–µ–º–∞ 1: Dropout –∫–∞–∫ –∞–Ω—Å–∞–º–±–ª—å**

**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:**  
–ï—Å–ª–∏ –æ–±—É—á–∞–µ–º —Å–µ—Ç—å —Å dropout p = 0.5 –≤ —Å–ª–æ–µ –∏–∑ n –Ω–µ–π—Ä–æ–Ω–æ–≤, –∫–∞–∂–¥–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è –æ–±—É—á–∞–µ—Ç –æ–¥–Ω—É –∏–∑ 2^n –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–æ–¥—Å–µ—Ç–µ–π.

**Inference:**  
–ò—Å–ø–æ–ª—å–∑—É–µ–º **—Å—Ä–µ–¥–Ω–µ–µ** –ø–æ –≤—Å–µ–º –ø–æ–¥—Å–µ—Ç—è–º (–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏: –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –Ω–µ–π—Ä–æ–Ω—ã —Å –≤–µ—Å–∞–º–∏, —É–º–Ω–æ–∂–µ–Ω–Ω—ã–º–∏ –Ω–∞ (1-p)).

**–ü—Ä–æ–±–ª–µ–º–∞ 2: –í—ã–±–æ—Ä p (dropout rate)**

**–≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞:**
- **Fully connected**: p = 0.5 (—Å—Ç–∞–Ω–¥–∞—Ä—Ç)
- **Convolutional**: p = 0.2-0.3 (–º–µ–Ω—å—à–µ, —Ç–∞–∫ –∫–∞–∫ –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
- **Input layer**: p = 0.1-0.2 (–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ, –º–æ–∂–µ–º –ø–æ—Ç–µ—Ä—è—Ç—å –¥–∞–Ω–Ω—ã–µ)

**–ü–æ–¥–±–æ—Ä:** —á–µ—Ä–µ–∑ cross-validation.

**–ü—Ä–æ–±–ª–µ–º–∞ 3: Spatial Dropout –¥–ª—è CNN**

**–û–±—ã—á–Ω—ã–π dropout –≤ CNN:**  
–í—ã–∫–ª—é—á–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏ –≤ feature map ‚Üí —Å–æ—Å–µ–¥–Ω–∏–µ –ø–∏–∫—Å–µ–ª–∏ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤—Å–µ —Ä–∞–≤–Ω–æ –ø—Ä–æ—Å–∞—á–∏–≤–∞–µ—Ç—Å—è.

**Spatial Dropout:**  
–í—ã–∫–ª—é—á–∞–µ—Ç **—Ü–µ–ª—ã–µ feature maps** (–≤—Å–µ –ø–∏–∫—Å–µ–ª–∏ –æ–¥–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞).

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**  
–í —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö —Å–ª–æ—è—Ö.

**–ü—Ä–æ–±–ª–µ–º–∞ 4: Dropout vs Batch Normalization**

**Batch Normalization** —Ç–∞–∫–∂–µ –¥–µ–π—Å—Ç–≤—É–µ—Ç –∫–∞–∫ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä (–¥–æ–±–∞–≤–ª—è–µ—Ç —à—É–º —á–µ—Ä–µ–∑ –±–∞—Ç—á-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏).

**–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞:**  
–° Batch Norm dropout –º–µ–Ω–µ–µ –∫—Ä–∏—Ç–∏—á–µ–Ω (–∏–Ω–æ–≥–¥–∞ –º–æ–∂–Ω–æ –æ–±–æ–π—Ç–∏—Å—å –±–µ–∑ –Ω–µ–≥–æ).

### 5) –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏

| –ú–µ—Ç–æ–¥ | –ì–¥–µ –ø—Ä–∏–º–µ–Ω—è—Ç—å | –≠—Ñ—Ñ–µ–∫—Ç | –í—ã—á–∏—Å–ª–µ–Ω–∏—è |
|-------|--------------|--------|-----------|
| **Dropout** | FC —Å–ª–æ–∏ | –°–Ω–∏–∂–∞–µ—Ç overfitting, –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ | –ü–æ—á—Ç–∏ –±–µ—Å–ø–ª–∞—Ç–Ω–æ |
| **Batch Norm** | –ü–æ—Å–ª–µ Conv/FC | –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è | –ù–µ–º–Ω–æ–≥–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ |
| **L2 Regularization** | –í–µ—Å–∞ | Shrinkage | –ë–µ—Å–ø–ª–∞—Ç–Ω–æ (–¥–æ–±–∞–≤–∫–∞ –∫ loss) |

---

## 7.4 Batch Normalization

### 1) –ò–Ω—Ç—É–∏—Ü–∏—è –∏ —Å—É—Ç—å

**–ü—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ (ELI5):**  
–ü—Ä–µ–¥—Å—Ç–∞–≤—å –∫–æ–Ω–≤–µ–π–µ—Ä –Ω–∞ —Ñ–∞–±—Ä–∏–∫–µ, –≥–¥–µ –∫–∞–∂–¥—ã–π —Ä–∞–±–æ—á–∏–π –ø–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª–∏ —Ä–∞–∑–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (—Ç–æ –æ–≥—Ä–æ–º–Ω—ã–µ, —Ç–æ –∫—Ä–æ—à–µ—á–Ω—ã–µ). –°–ª–æ–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å! Batch Norm ‚Äî —ç—Ç–æ **—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–µ—Ç–∞–ª–µ–π** –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞: –ø—Ä–∏–≤–æ–¥–∏–º –∏—Ö –∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–º—É –º–∞—Å—à—Ç–∞–±—É ‚Üí —Ä–∞–±–æ—á–∏–π –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ.

**–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏:**  
Batch Normalization –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Å–ª–æ—è (–ø—Ä–∏–≤–æ–¥–∏—Ç –∫ —Å—Ä–µ–¥–Ω–µ–º—É 0, –¥–∏—Å–ø–µ—Ä—Å–∏–∏ 1) **–ø–æ —Ç–µ–∫—É—â–µ–º—É batch**, –∑–∞—Ç–µ–º –ø—Ä–∏–º–µ–Ω—è–µ—Ç **learnable affine transformation** (Œ≥, Œ≤). –°—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ, –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à–∏–µ learning rates.

**–§–∏–∑–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª:**  
–†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É **internal covariate shift** ‚Äî –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–π –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è.

### 2) –ó–∞—á–µ–º –∏ –∫–æ–≥–¥–∞ (Business Value)

**–ö–∞–∫—É—é –ø—Ä–æ–±–ª–µ–º—É —Ä–µ—à–∞–µ—Ç:**
- **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è**: –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –Ω–µ –≤–∑—Ä—ã–≤–∞—é—Ç—Å—è –∏ –Ω–µ –∑–∞—Ç—É—Ö–∞—é—Ç
- **–ë–æ–ª—å—à–∏–µ learning rates**: –º–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å—Å—è –±—ã—Å—Ç—Ä–µ–µ
- **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è**: –Ω–µ–±–æ–ª—å—à–æ–π —ç—Ñ—Ñ–µ–∫—Ç —Å–Ω–∏–∂–µ–Ω–∏—è overfitting

**–ì–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:**
- **–ü–æ—á—Ç–∏ –≤–µ–∑–¥–µ –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö CNN**: –ø–æ—Å–ª–µ Conv —Å–ª–æ–µ–≤ (–¥–æ –∏–ª–∏ –ø–æ—Å–ª–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏)
- **Transformers, ResNets**

### 3) –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —è–¥—Ä–æ

**–î–ª—è batch –∏–∑ m –ø—Ä–∏–º–µ—Ä–æ–≤:**

**1. –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –∏ –¥–∏—Å–ø–µ—Ä—Å–∏—é –ø–æ batch:**
```
Œº_B = (1/m) Œ£ x_i
œÉ¬≤_B = (1/m) Œ£ (x_i - Œº_B)¬≤
```

**2. –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å:**
```
xÃÇ_i = (x_i - Œº_B) / ‚àö(œÉ¬≤_B + Œµ)
```
Œµ ‚Äî –º–∞–ª–æ–µ —á–∏—Å–ª–æ –¥–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ (10^(-5)).

**3. Learnable affine transformation:**
```
y_i = Œ≥ ¬∑ xÃÇ_i + Œ≤
```

**Œ≥, Œ≤** ‚Äî learnable –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–ø–æ–∑–≤–æ–ª—è—é—Ç —Å–µ—Ç–∏ "–æ—Ç–º–µ–Ω–∏—Ç—å" –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ).

**Training vs Inference:**

**Training:**  
–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ç–µ–∫—É—â–µ–≥–æ batch (Œº_B, œÉ¬≤_B).

**Inference:**  
–ò—Å–ø–æ–ª—å–∑—É–µ–º **running mean/variance** (—ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –≤—Å–µ–º batch –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è):
```
Œº_running = Œ± ¬∑ Œº_running + (1 - Œ±) ¬∑ Œº_B
œÉ¬≤_running = Œ± ¬∑ œÉ¬≤_running + (1 - Œ±) ¬∑ œÉ¬≤_B
```

### 4) Middle-level –Ω—é–∞–Ω—Å—ã

**–ü—Ä–æ–±–ª–µ–º–∞ 1: –ì–¥–µ —Å—Ç–∞–≤–∏—Ç—å Batch Norm?**

**–í–∞—Ä–∏–∞–Ω—Ç 1 (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç—å—è):**
```
Conv ‚Üí Batch Norm ‚Üí ReLU
```

**–í–∞—Ä–∏–∞–Ω—Ç 2 (—Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞):**
```
Conv ‚Üí ReLU ‚Üí Batch Norm
```

**–≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏:** –æ–±–∞ —Ä–∞–±–æ—Ç–∞—é—Ç, –≤–∞—Ä–∏–∞–Ω—Ç 2 –∏–Ω–æ–≥–¥–∞ —á—É—Ç—å –ª—É—á—à–µ.

**–ü—Ä–æ–±–ª–µ–º–∞ 2: –ú–∞–ª—ã–µ batch sizes**

**–ü—Ä–æ–±–ª–µ–º–∞:**  
–ï—Å–ª–∏ batch size –º–∞–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä, 4), —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ Œº_B, œÉ¬≤_B —à—É–º–Ω—ã–µ ‚Üí Batch Norm —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–ª–æ—Ö–æ.

**–†–µ—à–µ–Ω–∏–µ:**
- **Group Normalization**: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –≥—Ä—É–ø–ø–∞–º –∫–∞–Ω–∞–ª–æ–≤ (–Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç batch size)
- **Layer Normalization**: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –≤—Å–µ–º –∫–∞–Ω–∞–ª–∞–º –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ Transformers)

**–ü—Ä–æ–±–ª–µ–º–∞ 3: Batch Norm –∫–∞–∫ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ç–æ—Ä**

**–≠—Ñ—Ñ–µ–∫—Ç:**  
Batch Norm –¥–æ–±–∞–≤–ª—è–µ—Ç **—à—É–º** (–∫–∞–∂–¥—ã–π –ø—Ä–∏–º–µ—Ä –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç—Å—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ batch, –∞ –Ω–µ —Å–∞–º –ø–æ —Å–µ–±–µ).

**–°–ª–µ–¥—Å—Ç–≤–∏–µ:**  
–ù–µ–±–æ–ª—å—à–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è ‚Üí –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å dropout.

### 5) –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–π

| –ú–µ—Ç–æ–¥ | –ü–æ —á–µ–º—É –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è | –ó–∞–≤–∏—Å–∏—Ç –æ—Ç batch size | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
|-------|---------------------|---------------------|-------------------|
| **Batch Norm** | –ü–æ batch (N) | ‚úÖ –î–∞ | CNN (–±–æ–ª—å—à–∏–µ batch) |
| **Layer Norm** | –ü–æ features (C, H, W) | ‚ùå –ù–µ—Ç | Transformers, RNN |
| **Instance Norm** | –ü–æ –∫–∞–∂–¥–æ–º—É –ø—Ä–∏–º–µ—Ä—É –æ—Ç–¥–µ–ª—å–Ω–æ | ‚ùå –ù–µ—Ç | Style transfer |
| **Group Norm** | –ü–æ –≥—Ä—É–ø–ø–∞–º –∫–∞–Ω–∞–ª–æ–≤ | ‚ùå –ù–µ—Ç | –ú–∞–ª—ã–µ batch sizes |

---

---

## üìù –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–¥ (PyTorch)

### –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–π CNN

```python
import torch
import torch.nn as nn

class SimpleCNN(nn.Module):
    def __init__(self, num_classes=10):
        super(SimpleCNN, self).__init__()
        
        # –ë–ª–æ–∫ 1: –°–≤–µ—Ä—Ç–∫–∞ ‚Üí ReLU ‚Üí Win Pooling
        self.layer1 = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        # –í—Ö–æ–¥: 28x28x1 ‚Üí Conv(3x3, pad=1) ‚Üí 28x28x16 ‚Üí Pool(2x2) ‚Üí 14x14x16
        
        # –ë–ª–æ–∫ 2
        self.layer2 = nn.Sequential(
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        # –í—Ö–æ–¥: 14x14x16 ‚Üí ... ‚Üí –í—ã—Ö–æ–¥: 7x7x32
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (Fully Connected)
        self.fc = nn.Linear(7 * 7 * 32, num_classes)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.view(out.size(0), -1) # Flatten: (batch, 7*7*32)
        out = self.dropout(out)
        out = self.fc(out)
        return out

# –¢–µ—Å—Ç —Ä–∞–∑–º–µ—Ä–æ–≤
model = SimpleCNN()
dummy_input = torch.randn(1, 1, 28, 28) # batch=1, 1 –∫–∞–Ω–∞–ª (—á/–±), 28x28
output = model(dummy_input)
print("Output shape:", output.shape) # –¥–æ–ª–∂–Ω –±—ã—Ç—å [1, 10]
```

### –†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–æ–≤ –≤—ã—Ö–æ–¥–∞ —Å–≤–µ—Ä—Ç–∫–∏ (Summary Table)

–§–æ—Ä–º—É–ª–∞: $W_{out} = \lfloor \frac{W_{in} - K + 2P}{S} \rfloor + 1$


| –û–ø–µ—Ä–∞—Ü–∏—è | Input | Kernel/Pool | Padding | Stride | Output |
|----------|-------|-------------|---------|--------|--------|
| **Conv2d** | 224x224 | 3x3 | 1 | 1 | 224x224 |
| **Conv2d** | 224x224 | 3x3 | 0 (valid) | 1 | 222x222 |
| **Conv2d** | 224x224 | 7x7 | 3 | 2 | 112x112 |
| **MaxPool** | 112x112 | 2x2 | 0 | 2 | 56x56 |

---

## üéØ Q&A –¥–ª—è —ç–∫–∑–∞–º–µ–Ω–∞

**Q1: –ü–æ—á–µ–º—É —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ —Å–µ—Ç–∏ (CNN) –ª—É—á—à–µ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö (MLP) –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π?**
> 1. **Parameter Sharing**: –û–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —Ñ–∏–ª—å—Ç—Ä (–Ω–∞–±–æ—Ä –≤–µ—Å–æ–≤) —Å–∫–∞–Ω–∏—Ä—É–µ—Ç –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –≠—Ç–æ —Å–∏–ª—å–Ω–æ —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å.
> 2. **–õ–æ–∫–∞–ª—å–Ω–æ—Å—Ç—å**: CNN —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Å–æ—Å–µ–¥–Ω–∏–µ –ø–∏–∫—Å–µ–ª–∏ –≤–∞–∂–Ω—ã), MLP –ø—Ä–æ—Å—Ç–æ –≤—ã—Ç—è–≥–∏–≤–∞–µ—Ç –≤—Å–µ –≤ –≤–µ–∫—Ç–æ—Ä, —Ç–µ—Ä—è—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
> 3. **–ò–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ —Å–¥–≤–∏–≥—É**: –ö–æ—Ç –≤ –ª–µ–≤–æ–º —É–≥–ª—É –∏ –∫–æ—Ç –≤ –ø—Ä–∞–≤–æ–º —É–≥–ª—É –∞–∫—Ç–∏–≤–∏—Ä—É—é—Ç –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ —Ñ–∏–ª—å—Ç—Ä—ã.

**Q2: –ß—Ç–æ –¥–µ–ª–∞–µ—Ç Max Pooling?**
> –£–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å feature map, –≤—ã–±–∏—Ä–∞—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –æ–∫–Ω–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2x2). –≠—Ç–æ —Å–Ω–∏–∂–∞–µ—Ç –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—É—é –Ω–∞–≥—Ä—É–∑–∫—É –∏ –¥–µ–ª–∞–µ—Ç —Å–µ—Ç—å —É—Å—Ç–æ–π—á–∏–≤–æ–π –∫ –Ω–µ–±–æ–ª—å—à–∏–º —Å–¥–≤–∏–≥–∞–º –∏ –∏—Å–∫–∞–∂–µ–Ω–∏—è–º –æ–±—ä–µ–∫—Ç–∞.

**Q3: –ó–∞—á–µ–º –Ω—É–∂–µ–Ω Padding?**
> –ß—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ —Å–≤–µ—Ä—Ç–∫–∏ (padding='same') –∏ –Ω–µ —Ç–µ—Ä—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ –∫—Ä–∞—è—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–≥–¥–µ —Ñ–∏–ª—å—Ç—Ä "–≤—ã–ª–µ–∑–∞–µ—Ç" –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã –±–µ–∑ –ø–∞–¥–¥–∏–Ω–≥–∞).

**Q4: –ü–æ—á–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤ –æ–±—ã—á–Ω–æ —Ä–∞—Å—Ç–µ—Ç —Å –≥–ª—É–±–∏–Ω–æ–π —Å–µ—Ç–∏, –∞ —Ä–∞–∑–º–µ—Ä (HxW) –ø–∞–¥–∞–µ—Ç?**
> –í –Ω–∞—á–∞–ª–µ —Å–µ—Ç–∏ –º—ã –∏—â–µ–º –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ª–∏–Ω–∏–∏, —É–≥–ª—ã) ‚Äî –∏—Ö –º–∞–ª–æ, –Ω–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –≤—ã—Å–æ–∫–æ–µ. –í –≥–ª—É–±–∏–Ω–µ –º—ã –∫–æ–º–±–∏–Ω–∏—Ä—É–µ–º –∏—Ö –≤ —Å–ª–æ–∂–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã (–≥–ª–∞–∑–∞, –∫–æ–ª–µ—Å–∞) ‚Äî –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –º–Ω–æ–≥–æ (–∫–∞–Ω–∞–ª–æ–≤ –±–æ–ª—å—à–µ), –Ω–æ —Ç–æ—á–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø–∏–∫—Å–µ–ª—è —É–∂–µ –Ω–µ —Ç–∞–∫ –≤–∞–∂–Ω–æ (—Ä–∞–∑–º–µ—Ä –º–µ–Ω—å—à–µ).

---

## –†–µ–∑—é–º–µ –º–æ–¥—É–ª—è

Computer Vision —Å CNN ‚Äî —ç—Ç–æ **–∏–µ—Ä–∞—Ä—Ö–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**:
- **Convolution**: –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, parameter sharing, translation invariance
- **Pooling**: downsampling, –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ –º–∞–ª—ã–º —Å–¥–≤–∏–≥–∞–º
- **Dropout**: —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥—Å–µ—Ç–µ–π
- **Batch Normalization**: —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è, internal covariate shift

–≠—Ç–∏ –±–ª–æ–∫–∏ ‚Äî –æ—Å–Ω–æ–≤–∞ –≤—Å–µ—Ö —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö CNN (ResNet, EfficientNet, Vision Transformers)!
