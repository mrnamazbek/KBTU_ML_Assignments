# –ú–æ–¥—É–ª—å 1: –û—Å–Ω–æ–≤—ã Machine Learning

## 1.1 k-Nearest Neighbors (k-NN)

### 1) –ò–Ω—Ç—É–∏—Ü–∏—è –∏ —Å—É—Ç—å

**–ü—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ (ELI5):**  
–ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ —Ç—ã –ø–µ—Ä–µ–µ—Ö–∞–ª –≤ –Ω–æ–≤—ã–π —Ä–∞–π–æ–Ω –∏ —Ö–æ—á–µ—à—å –ø–æ–Ω—è—Ç—å, –∫–∞–∫–∞—è —Ç–∞–º —Å—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –∫–≤–∞—Ä—Ç–∏—Ä. –¢—ã —Å–º–æ—Ç—Ä–∏—à—å –Ω–∞ 5 –±–ª–∏–∂–∞–π—à–∏—Ö –∫ —Ç–µ–±–µ –¥–æ–º–æ–≤ –∏ —É—Å—Ä–µ–¥–Ω—è–µ—à—å –∏—Ö —Ü–µ–Ω—ã. –≠—Ç–æ –∏ –µ—Å—Ç—å k-NN: —Ç—ã —Å–º–æ—Ç—Ä–∏—à—å –Ω–∞ k –±–ª–∏–∂–∞–π—à–∏—Ö "—Å–æ—Å–µ–¥–µ–π" –≤ –¥–∞–Ω–Ω—ã—Ö –∏ –¥–µ–ª–∞–µ—à—å –≤—ã–≤–æ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π.

**–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏:**  
k-NN ‚Äî —ç—Ç–æ **–Ω–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥** (–Ω–µ –¥–µ–ª–∞–µ—Ç –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–π –æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö), –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –ø—Ä–∏–Ω—Ü–∏–ø–µ **–ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç–∏**: –æ–±—ä–µ–∫—Ç—ã —Å –ø–æ—Ö–æ–∂–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏–º–µ—é—Ç –ø–æ—Ö–æ–∂–∏–µ —Ü–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è. –ê–ª–≥–æ—Ä–∏—Ç–º –Ω–∞—Ö–æ–¥–∏—Ç k –±–ª–∏–∂–∞–π—à–∏—Ö –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –≥–æ–ª–æ—Å–æ–≤ (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è) –∏–ª–∏ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è (—Ä–µ–≥—Ä–µ—Å—Å–∏—è).

**–§–∏–∑–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª:**  
–ú–µ—Ç–æ–¥ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ **–º–µ—Ç—Ä–∏–∫–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è** (–æ–±—ã—á–Ω–æ –µ–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ) –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤. –ß–µ–º –º–µ–Ω—å—à–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ, —Ç–µ–º –±–æ–ª–µ–µ "–ø–æ—Ö–æ–∂–∏" –æ–±—ä–µ–∫—Ç—ã.

### 2) –ó–∞—á–µ–º –∏ –∫–æ–≥–¥–∞ (Business Value)

**–ö–∞–∫—É—é –ø—Ä–æ–±–ª–µ–º—É —Ä–µ—à–∞–µ—Ç:**
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏—è **–±–µ–∑ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏** (lazy learning)
- –†–∞–±–æ—Ç–∞–µ—Ç —Å **–Ω–µ–ª–∏–Ω–µ–π–Ω—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏** "–∏–∑ –∫–æ—Ä–æ–±–∫–∏"
- –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è **–º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö** (small data regime)

**–ì–¥–µ —ç—Ç–æ –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç:**
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã**: –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π/—Ç–æ–≤–∞—Ä–æ–≤ (collaborative filtering)
- **–ú–µ–¥–∏—Ü–∏–Ω–∞**: –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤
- **–§–∏–Ω–∞–Ω—Å—ã**: –æ—Ü–µ–Ω–∫–∞ –∫—Ä–µ–¥–∏—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –ø–æ –ø–æ—Ö–æ–∂–∏–º –∫–ª–∏–µ–Ω—Ç–∞–º
- **Computer Vision**: —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –æ–±—Ä–∞–∑–æ–≤ (–≤ —Å–≤—è–∑–∫–µ —Å feature extraction)

**–ö–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å –Ω–µ–ª—å–∑—è:**
- ‚ùå –í—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (**–ø—Ä–æ–∫–ª—è—Ç–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏**)
- ‚ùå –ë–æ–ª—å—à–∏–µ –¥–∞—Ç–∞—Å–µ—Ç—ã (–º–µ–¥–ª–µ–Ω–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å: O(n) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è)
- ‚ùå –î–∞–Ω–Ω—ã–µ —Å —Ä–∞–∑–Ω—ã–º–∏ –º–∞—Å—à—Ç–∞–±–∞–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Ç—Ä–µ–±—É–µ—Ç—Å—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)
- ‚ùå –®—É–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–≤—ã–±—Ä–æ—Å—ã —Å–∏–ª—å–Ω–æ –≤–ª–∏—è—é—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç)

### 3) –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —è–¥—Ä–æ

**–ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ:**
```
d(x, x_i) = ‚àö(Œ£(x_j - x_i_j)¬≤)
```

**–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (–≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ):**
```
≈∑ = mode{y_i : x_i ‚àà N_k(x)}
```
–≥–¥–µ N_k(x) ‚Äî –º–Ω–æ–∂–µ—Å—Ç–≤–æ k –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π —Ç–æ—á–∫–∏ x.

**–†–µ–≥—Ä–µ—Å—Å–∏—è (—Å—Ä–µ–¥–Ω–µ–µ):**
```
≈∑ = (1/k) Œ£ y_i, –≥–¥–µ x_i ‚àà N_k(x)
```

**–í–∑–≤–µ—à–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç:**
```
≈∑ = Œ£ w_i ¬∑ y_i / Œ£ w_i,  –≥–¥–µ w_i = 1/d(x, x_i)
```
–ë–æ–ª–µ–µ –±–ª–∏–∑–∫–∏–µ —Å–æ—Å–µ–¥–∏ –∏–º–µ—é—Ç –±–æ–ª—å—à–∏–π –≤–µ—Å.

### 4) Middle-level –Ω—é–∞–Ω—Å—ã

**–ü—Ä–æ–±–ª–µ–º–∞ 1: –ü—Ä–æ–∫–ª—è—Ç–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (Curse of Dimensionality)**

**–°—É—Ç—å:**  
–ü—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ–±—ä–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ —Ä–∞—Å—Ç–µ—Ç —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ, –∏ –≤—Å–µ —Ç–æ—á–∫–∏ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è "–¥–∞–ª–µ–∫–æ" –¥—Ä—É–≥ –æ—Ç –¥—Ä—É–≥–∞. –ü–æ–Ω—è—Ç–∏–µ "–±–ª–∏–∑–æ—Å—Ç–∏" —Ç–µ—Ä—è–µ—Ç —Å–º—ã—Å–ª.

**–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞:**  
–í d-–º–µ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ –æ–±—ä–µ–º –≥–∏–ø–µ—Ä–∫—É–±–∞ —Ä–∞—Å—Ç–µ—Ç –∫–∞–∫ L^d, –∞ –æ–±—ä–µ–º –≥–∏–ø–µ—Ä—Å—Ñ–µ—Ä—ã –∫–∞–∫ r^d. –ü—Ä–∏ –±–æ–ª—å—à–æ–º d –ø–æ—á—Ç–∏ –≤–µ—Å—å –æ–±—ä–µ–º –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ—Ç—Å—è —É –≥—Ä–∞–Ω–∏—Ü.

**–ü—Ä–∏–º–µ—Ä:**  
–í 1D –¥–ª—è –ø–æ–∫—Ä—ã—Ç–∏—è 10% –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –Ω—É–∂–Ω–æ 10% –¥–∞–Ω–Ω—ã—Ö. –í 10D –¥–ª—è –ø–æ–∫—Ä—ã—Ç–∏—è 10% –æ–±—ä–µ–º–∞ –Ω—É–∂–Ω–æ 10^(1/10) ‚âà 79% –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∞–∂–¥–æ–π –æ—Å–∏!

**–†–µ—à–µ–Ω–∏–µ:**
- –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏: **PCA, t-SNE, UMAP**
- –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: **feature selection** (Lasso, mutual information)
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ **—Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫** (Manhattan, Minkowski)

**–ü—Ä–æ–±–ª–µ–º–∞ 2: –í—ã–±–æ—Ä k (–≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä)**

- **k —Å–ª–∏—à–∫–æ–º –º–∞–ª (k=1)**: –∞–ª–≥–æ—Ä–∏—Ç–º –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è, —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —à—É–º—É
- **k —Å–ª–∏—à–∫–æ–º –≤–µ–ª–∏–∫**: –≥—Ä–∞–Ω–∏—Ü–∞ —Ä–∞–∑–º—ã–≤–∞–µ—Ç—Å—è, –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏–µ (underfitting)

**–≠–º–ø–∏—Ä–∏—á–µ—Å–∫–æ–µ –ø—Ä–∞–≤–∏–ª–æ:**  
k = ‚àön (–≥–¥–µ n ‚Äî —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏), –∑–∞—Ç–µ–º –ø–æ–¥–±–æ—Ä —á–µ—Ä–µ–∑ **–∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é**.

**–ü—Ä–æ–±–ª–µ–º–∞ 3: –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å**

- **–û–±—É—á–µ–Ω–∏–µ**: O(1) ‚Äî –ø—Ä–æ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
- **–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ**: O(n¬∑d¬∑log k) ‚Äî –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –∏—â–µ–º k —Å–æ—Å–µ–¥–µ–π

**–†–µ—à–µ–Ω–∏–µ:**
- **KD-Tree, Ball Tree**: O(log n) –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ—Å–µ–¥–µ–π (—Ä–∞–±–æ—Ç–∞–µ—Ç –ø–ª–æ—Ö–æ –ø—Ä–∏ d > 20)
- **Approximate Nearest Neighbors** (ANN): Annoy, FAISS, HNSW

**–ü—Ä–æ–±–ª–µ–º–∞ 4: –ú–∞—Å—à—Ç–∞–± –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**

–ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –±–æ–ª—å—à–∏–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—Ç –≤ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏.

**–ü—Ä–∏–º–µ—Ä:**  
–í–æ–∑—Ä–∞—Å—Ç [0-100] –∏ –∑–∞—Ä–ø–ª–∞—Ç–∞ [0-1,000,000] ‚Äî –∑–∞—Ä–ø–ª–∞—Ç–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–ø—Ä–µ–¥–µ–ª–∏—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ.

**–†–µ—à–µ–Ω–∏–µ:**
- **–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è**: (x - Œº) / œÉ
- **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è**: (x - min) / (max - min)

### 5) –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞–º–∏

| –ú–µ—Ç–æ–¥ | –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã | –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã |
|-------|----------------|----------------|
| **k-NN** | ‚úÖ –ù–µ—Ç –æ–±—É—á–µ–Ω–∏—è<br>‚úÖ –ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã<br>‚úÖ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º | ‚ùå –ú–µ–¥–ª–µ–Ω–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å<br>‚ùå –ü—Ä–æ–∫–ª—è—Ç–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏<br>‚ùå –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —à—É–º—É |
| **Logistic Regression** | ‚úÖ –ë—ã—Å—Ç—Ä—ã–π<br>‚úÖ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏<br>‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∏ d >> n | ‚ùå –¢–æ–ª—å–∫–æ –ª–∏–Ω–µ–π–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã<br>‚ùå –¢—Ä–µ–±—É–µ—Ç feature engineering |
| **Random Forest** | ‚úÖ –ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏<br>‚úÖ –£—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º | ‚ùå –ú–µ–¥–ª–µ–Ω–Ω—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å<br>‚ùå –ú–µ–Ω–µ–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º |

---

## 1.2 Ordinary Least Squares (OLS)

### 1) –ò–Ω—Ç—É–∏—Ü–∏—è –∏ —Å—É—Ç—å

**–ü—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ (ELI5):**  
–£ —Ç–µ–±—è –µ—Å—Ç—å —Ç–æ—á–∫–∏ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ, –∏ —Ç—ã —Ö–æ—á–µ—à—å –ø—Ä–æ–≤–µ—Å—Ç–∏ —á–µ—Ä–µ–∑ –Ω–∏—Ö –ø—Ä—è–º—É—é –ª–∏–Ω–∏—é —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∞ –±—ã–ª–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–ª–∏–∑–∫–∞ –∫–æ –≤—Å–µ–º —Ç–æ—á–∫–∞–º. OLS –Ω–∞—Ö–æ–¥–∏—Ç —ç—Ç—É "–Ω–∞–∏–ª—É—á—à—É—é" –ø—Ä—è–º—É—é, –º–∏–Ω–∏–º–∏–∑–∏—Ä—É—è —Å—É–º–º—É –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –æ—Ç —Ç–æ—á–µ–∫ –¥–æ –ª–∏–Ω–∏–∏.

**–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏:**  
OLS ‚Äî —ç—Ç–æ –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ **–ª–∏–Ω–µ–π–Ω–æ–π –º–æ–¥–µ–ª–∏** –ø—É—Ç–µ–º –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ —Å—É–º–º—ã –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –æ—Å—Ç–∞—Ç–∫–æ–≤ (–æ—à–∏–±–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è). –≠—Ç–æ **–æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –Ω–µ—Å–º–µ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞** –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–µ–¥–ø–æ—Å—ã–ª–æ–∫ —Ç–µ–æ—Ä–µ–º—ã –ì–∞—É—Å—Å–∞-–ú–∞—Ä–∫–æ–≤–∞.

**–§–∏–∑–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª:**  
–ö–≤–∞–¥—Ä–∞—Ç—ã –æ—à–∏–±–æ–∫ –Ω–∞–∫–∞–∑—ã–≤–∞—é—Ç –±–æ–ª—å—à–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è —Å–∏–ª—å–Ω–µ–µ, —á–µ–º –º–∞–ª—ã–µ. –≠—Ç–æ –¥–µ–ª–∞–µ—Ç –º–µ—Ç–æ–¥ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º –∫ –≤—ã–±—Ä–æ—Å–∞–º, –Ω–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º.

### 2) –ó–∞—á–µ–º –∏ –∫–æ–≥–¥–∞ (Business Value)

**–ö–∞–∫—É—é –ø—Ä–æ–±–ª–µ–º—É —Ä–µ—à–∞–µ—Ç:**
- –ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ **–ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π** –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
- **–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ** –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –≤–µ–ª–∏—á–∏–Ω
- **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤–ª–∏—è–Ω–∏—è** –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Ä–µ–≥—Ä–µ—Å—Å–∏–∏)

**–ì–¥–µ —ç—Ç–æ –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç:**
- **–§–∏–Ω–∞–Ω—Å—ã**: –ø—Ä–æ–≥–Ω–æ–∑ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –∞–∫—Ü–∏–π, risk modeling
- **–≠–∫–æ–Ω–æ–º–µ—Ç—Ä–∏–∫–∞**: –æ—Ü–µ–Ω–∫–∞ —Å–ø—Ä–æ—Å–∞, —ç–ª–∞—Å—Ç–∏—á–Ω–æ—Å—Ç–∏ —Ü–µ–Ω
- **–ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å**: –ø—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
- **–ú–µ–¥–∏—Ü–∏–Ω–∞**: –∞–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –Ω–∞ –∑–¥–æ—Ä–æ–≤—å–µ (–¥–æ–∑–∏—Ä–æ–≤–∫–∞ ‚Üí —ç—Ñ—Ñ–µ–∫—Ç)

**–ö–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å –Ω–µ–ª—å–∑—è:**
- ‚ùå –ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–Ω—É–∂–Ω—ã –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–ª–∏ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏)
- ‚ùå –ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å (—Å–∏–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏)
- ‚ùå –ì–µ—Ç–µ—Ä–æ—Å–∫–µ–¥–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å (–Ω–µ–ø–æ—Å—Ç–æ—è–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è –æ—à–∏–±–æ–∫)
- ‚ùå –í—ã–±—Ä–æ—Å—ã (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Huber loss –∏–ª–∏ RANSAC)

### 3) –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —è–¥—Ä–æ

**–ú–æ–¥–µ–ª—å:**
```
y = XŒ≤ + Œµ
```
–≥–¥–µ:
- y ‚àà ‚Ñù‚Åø ‚Äî –≤–µ–∫—Ç–æ—Ä —Ü–µ–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
- X ‚àà ‚Ñù‚ÅøÀ£·µñ ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (design matrix)
- Œ≤ ‚àà ‚Ñù·µñ ‚Äî –≤–µ–∫—Ç–æ—Ä –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤
- Œµ ‚àº N(0, œÉ¬≤I) ‚Äî –æ—à–∏–±–∫–∏ (Gaussian noise)

**–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å (MSE):**
```
L(Œ≤) = ||y - XŒ≤||¬≤ = Œ£(y_i - x_i^T Œ≤)¬≤
```

**–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ (–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ):**
```
Œ≤ÃÇ = (X^T X)^(-1) X^T y
```

**–£—Å–ª–æ–≤–∏–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏:**  
–ú–∞—Ç—Ä–∏—Ü–∞ X^T X –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å **–æ–±—Ä–∞—Ç–∏–º–æ–π** (–ø–æ–ª–Ω–æ–≥–æ —Ä–∞–Ω–≥–∞). –ò–Ω–∞—á–µ ‚Äî **–º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å**.

**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:**
```
≈∑ = XŒ≤ÃÇ
```

**–û—Å—Ç–∞—Ç–∫–∏:**
```
e = y - ≈∑
```

### 4) Middle-level –Ω—é–∞–Ω—Å—ã

**–ü—Ä–æ–±–ª–µ–º–∞ 1: –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ vs –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫**

| –ú–µ—Ç–æ–¥ | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
|-------|-----------|-------------------|
| **–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ** | O(p¬≥ + np¬≤) | –ú–∞–ª–æ–µ p (p < 10,000), –Ω—É–∂–Ω–æ —Ç–æ—á–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ |
| **–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫** | O(iterations ¬∑ np) | –ë–æ–ª—å—à–æ–µ p, –æ–Ω–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏–µ, —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è |

**–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫:**
```
Œ≤^(t+1) = Œ≤^(t) - Œ± ¬∑ ‚àáL(Œ≤^(t))
‚àáL(Œ≤) = -2X^T(y - XŒ≤)
```

**–ü—Ä–æ–±–ª–µ–º–∞ 2: –ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å**

**–ü—Ä–∏–∑–Ω–∞–∫–∏:**  
–î–≤–∞ –∏–ª–∏ –±–æ–ª–µ–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ —Å–∏–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–ª–æ—â–∞–¥—å –¥–æ–º–∞ –≤ –º¬≤ –∏ –≤ —Ñ—É—Ç–∞—Ö¬≤).

**–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è:**
- –ú–∞—Ç—Ä–∏—Ü–∞ X^T X –±–ª–∏–∑–∫–∞ –∫ –≤—ã—Ä–æ–∂–¥–µ–Ω–Ω–æ–π ‚Üí **–Ω–µ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å** (X^T X)^(-1)
- –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –∏–º–µ—é—Ç **–æ–≥—Ä–æ–º–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è** –∏ **–≤—ã—Å–æ–∫—É—é –¥–∏—Å–ø–µ—Ä—Å–∏—é**
- –ú–∞–ª–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö ‚Üí —Å–∏–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ Œ≤

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:**
- **VIF (Variance Inflation Factor)**: VIF > 10 ‚Äî –ø—Ä–æ–±–ª–µ–º–∞
  ```
  VIF_j = 1 / (1 - R¬≤_j)
  ```
  –≥–¥–µ R¬≤_j ‚Äî R¬≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ j-–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ –Ω–∞ –æ—Å—Ç–∞–ª—å–Ω—ã–µ.

**–†–µ—à–µ–Ω–∏–µ:**
- –£–¥–∞–ª–∏—Ç—å –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- **PCA** (–≥–ª–∞–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)
- **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è**: Ridge (L2)

**–ü—Ä–æ–±–ª–µ–º–∞ 3: –í—ã–±—Ä–æ—Å—ã**

OLS –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç –∫–≤–∞–¥—Ä–∞—Ç—ã ‚Üí –≤—ã–±—Ä–æ—Å—ã –∏–º–µ—é—Ç **–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ**.

**–†–µ—à–µ–Ω–∏–µ:**
- **Robust regression**: Huber loss, RANSAC
- –£–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ (Cook's distance, leverage)

**–ü—Ä–æ–±–ª–µ–º–∞ 4: –ü—Ä–µ–¥–ø–æ—Å—ã–ª–∫–∏ –º–æ–¥–µ–ª–∏ (Assumptions)**

1. **–õ–∏–Ω–µ–π–Ω–æ—Å—Ç—å**: E[y|X] = XŒ≤
2. **–ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å** –æ—à–∏–±–æ–∫: cov(Œµ_i, Œµ_j) = 0
3. **–ì–æ–º–æ—Å–∫–µ–¥–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å**: Var(Œµ_i) = œÉ¬≤ (–ø–æ—Å—Ç–æ—è–Ω–Ω–∞—è)
4. **–ù–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å** –æ—à–∏–±–æ–∫: Œµ_i ‚àº N(0, œÉ¬≤)
5. **–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏**

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:**
- Residual plots (–æ—Å—Ç–∞—Ç–∫–∏ vs –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è)
- Q-Q plot (–Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å)
- Breusch-Pagan test (–≥–æ–º–æ—Å–∫–µ–¥–∞—Å—Ç–∏—á–Ω–æ—Å—Ç—å)

### 5) –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞–º–∏

| –ú–µ—Ç–æ–¥ | –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ | –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ |
|-------|-------------|-----------|
| **OLS** | ‚úÖ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å<br>‚úÖ –ë—ã—Å—Ç—Ä—ã–π<br>‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã | ‚ùå –¢–æ–ª—å–∫–æ –ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏<br>‚ùå –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –≤—ã–±—Ä–æ—Å–∞–º<br>‚ùå –ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å |
| **Ridge (L2)** | ‚úÖ –†–µ—à–∞–µ—Ç –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å<br>‚úÖ –°—Ç–∞–±–∏–ª—å–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã | ‚ùå –í—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ—Å—Ç–∞—é—Ç—Å—è (–Ω–µ –¥–µ–ª–∞–µ—Ç feature selection) |
| **Lasso (L1)** | ‚úÖ Feature selection<br>‚úÖ –£—Å—Ç–æ–π—á–∏–≤ –∫ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏ | ‚ùå –ù–µ—Å—Ç–∞–±–∏–ª–µ–Ω –ø—Ä–∏ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö |
| **Polynomial Regression** | ‚úÖ –ù–µ–ª–∏–Ω–µ–π–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ | ‚ùå –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π —Å—Ç–µ–ø–µ–Ω–∏ |

---

## 1.3 Bias-Variance Trade-off

### 1) –ò–Ω—Ç—É–∏—Ü–∏—è –∏ —Å—É—Ç—å

**–ü—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ (ELI5):**  
–ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ —Ç—ã —Å—Ç—Ä–µ–ª—è–µ—à—å –ø–æ –º–∏—à–µ–Ω–∏:
- **Bias (—Å–º–µ—â–µ–Ω–∏–µ)** ‚Äî –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ç–≤–æ–∏ –≤—ã—Å—Ç—Ä–µ–ª—ã —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω—ã –æ—Ç —Ü–µ–Ω—Ç—Ä–∞
- **Variance (—Ä–∞–∑–±—Ä–æ—Å)** ‚Äî –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–±—Ä–æ—Å–∞–Ω—ã –≤—ã—Å—Ç—Ä–µ–ª—ã –¥—Ä—É–≥ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥—Ä—É–≥–∞

–ò–¥–µ–∞–ª—å–Ω—ã–π —Å—Ç—Ä–µ–ª–æ–∫ ‚Äî –≤ —Ü–µ–Ω—Ç—Ä–µ –∏ –∫—É—á–Ω–æ. –ù–æ –æ–±—ã—á–Ω–æ –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è –≤—ã–±–∏—Ä–∞—Ç—å: –ª–∏–±–æ —Å—Ç—Ä–µ–ª—è—Ç—å —Ç–æ—á–Ω–æ –≤ —Å—Ä–µ–¥–Ω–µ–º, –Ω–æ —Ä–∞–∑–±—Ä–æ—Å–∞–Ω–Ω–æ (low bias, high variance), –ª–∏–±–æ –∫—É—á–Ω–æ, –Ω–æ –º–∏–º–æ (high bias, low variance).

**–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏:**  
–≠—Ç–æ **—Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ –æ—à–∏–±–∫–∏** –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç—Ä–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞: —Å–º–µ—â–µ–Ω–∏–µ (–Ω–∞—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å —Å–∏—Å—Ç–µ–º–Ω–æ –æ—à–∏–±–∞–µ—Ç—Å—è), –¥–∏—Å–ø–µ—Ä—Å–∏—é (–Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –º–µ–Ω—è—é—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –æ–±—É—á–∞—é—â–∏—Ö –≤—ã–±–æ—Ä–∫–∞—Ö) –∏ –Ω–µ—É—Å—Ç—Ä–∞–Ω–∏–º—ã–π —à—É–º.

**–§–∏–∑–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª:**  
–õ—é–±–∞—è –º–æ–¥–µ–ª—å ‚Äî —ç—Ç–æ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É **—Å–ª–æ–∂–Ω–æ—Å—Ç—å—é** (—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å—é —É–ª–æ–≤–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã) –∏ **–æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å—é** (—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å—é –∫ —à—É–º—É).

### 2) –ó–∞—á–µ–º –∏ –∫–æ–≥–¥–∞ (Business Value)

**–ö–∞–∫—É—é –ø—Ä–æ–±–ª–µ–º—É —Ä–µ—à–∞–µ—Ç:**
- –ü–æ–Ω–∏–º–∞–Ω–∏–µ **–ø—Ä–∏—Ä–æ–¥—ã –æ—à–∏–±–æ–∫** –º–æ–¥–µ–ª–∏
- –í—ã–±–æ—Ä **–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏** –º–æ–¥–µ–ª–∏
- –û–±—ä—è—Å–Ω–µ–Ω–∏–µ **–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è** –∏ **–Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—è**

**–ì–¥–µ —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ:**
- **–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏**: –∫–æ–≥–¥–∞ —Ä–µ—à–∞–µ—Ç–µ, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –∏–ª–∏ deep learning
- **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è**: –ø–æ–Ω–∏–º–∞–Ω–∏–µ, –∫–∞–∫–æ–π —Ç–∏–ø —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–µ–Ω
- **–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞**: –ø–æ—á–µ–º—É –º–æ–¥–µ–ª—å –ø–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ —Ç–µ—Å—Ç–µ

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è:**
- High bias ‚Üí **—É—Å–ª–æ–∂–Ω–∏—Ç—å –º–æ–¥–µ–ª—å** (–±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å, –≥–ª—É–±–∂–µ —Å–µ—Ç—å)
- High variance ‚Üí **—É–ø—Ä–æ—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª—å** (—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è, –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö)

### 3) –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —è–¥—Ä–æ

**–î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –æ—à–∏–±–∫–∏:**

–ü—É—Å—Ç—å ≈∑(x) ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏, y ‚Äî –∏—Å—Ç–∏–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, f(x) ‚Äî –∏—Å—Ç–∏–Ω–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å.

```
E[(y - ≈∑)¬≤] = Bias¬≤ + Variance + Irreducible Error
```

**–ü–æ–¥—Ä–æ–±–Ω–æ:**

1. **Bias¬≤** (–∫–≤–∞–¥—Ä–∞—Ç —Å–º–µ—â–µ–Ω–∏—è):
```
Bias¬≤ = (E[≈∑(x)] - f(x))¬≤
```
–ù–∞—Å–∫–æ–ª—å–∫–æ –≤ —Å—Ä–µ–¥–Ω–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç –∏—Å—Ç–∏–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏.

2. **Variance** (–¥–∏—Å–ø–µ—Ä—Å–∏—è):
```
Variance = E[(≈∑(x) - E[≈∑(x)])¬≤]
```
–ù–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –º–µ–Ω—è—é—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –æ–±—É—á–∞—é—â–∏—Ö –≤—ã–±–æ—Ä–∫–∞—Ö.

3. **Irreducible Error** (–Ω–µ—É—Å—Ç—Ä–∞–Ω–∏–º–∞—è –æ—à–∏–±–∫–∞):
```
œÉ¬≤ = E[(y - f(x))¬≤]
```
–®—É–º –≤ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞—Ç—å.

**–ü–æ–ª–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞:**
```
MSE = E[(y - ≈∑)¬≤] = (E[≈∑] - f)¬≤ + E[(≈∑ - E[≈∑])¬≤] + œÉ¬≤
      |_____________|   |________________|   |__|
           Bias¬≤            Variance        Noise
```

### 4) Middle-level –Ω—é–∞–Ω—Å—ã

**–ü—Ä–æ–±–ª–µ–º–∞ 1: Trade-off (–∫–æ–º–ø—Ä–æ–º–∏—Å—Å)**

–ü—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏:
- **Bias ‚Üì** ‚Äî –º–æ–¥–µ–ª—å –ª—É—á—à–µ "–ø–æ–¥–≥–æ–Ω—è–µ—Ç—Å—è" –ø–æ–¥ –¥–∞–Ω–Ω—ã–µ
- **Variance ‚Üë** ‚Äî –º–æ–¥–µ–ª—å —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ

**–ì—Ä–∞—Ñ–∏—á–µ—Å–∫–∏:**

```
    Error ‚ñ≤
          ‚îÇ         ‚ï±‚ï≤ Total Error
          ‚îÇ        ‚ï±  ‚ï≤
          ‚îÇ    ‚ï±‚ï≤  ‚ï±    ‚ï≤
          ‚îÇ   ‚ï±  ‚ï≤‚ï±      ‚ï≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Bias¬≤
          ‚îÇ  ‚ï± Variance   ‚ï≤
          ‚îÇ ‚ï±              ‚ï≤
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Model Complexity
            Simple    Optimal    Complex
                         ‚¨Ü
                    Sweet Spot
```

**–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å** ‚Äî —Ç–∞–º, –≥–¥–µ —Å—É–º–º–∞—Ä–Ω–∞—è –æ—à–∏–±–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞.

**–ü—Ä–æ–±–ª–µ–º–∞ 2: –ü—Ä–∏–º–µ—Ä—ã –º–æ–¥–µ–ª–µ–π**

| –¢–∏–ø –º–æ–¥–µ–ª–∏ | Bias | Variance | –ü—Ä–∏–º–µ—Ä |
|------------|------|----------|--------|
| **–ü—Ä–æ—Å—Ç—ã–µ** | High | Low | –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è, Naive Bayes |
| **–°—Ä–µ–¥–Ω–∏–µ** | Medium | Medium | Decision Tree (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –≥–ª—É–±–∏–Ω—ã) |
| **–°–ª–æ–∂–Ω—ã–µ** | Low | High | Deep Neural Networks, KNN (k=1) |

**–ü—Ä–æ–±–ª–µ–º–∞ 3: –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è (Overfitting)**

**–°–∏–º–ø—Ç–æ–º—ã:**
- Train error << Test error (–±–æ–ª—å—à–æ–π —Ä–∞–∑—Ä—ã–≤)
- Model performance —É—Ö—É–¥—à–∞–µ—Ç—Å—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –ú–æ–¥–µ–ª—å "–∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç" —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

**High Variance —Å—Ü–µ–Ω–∞—Ä–∏–π:**
```python
Train MSE: 0.01
Test MSE:  0.50  ‚Üê –ø—Ä–æ–±–ª–µ–º–∞!
```

**–†–µ—à–µ–Ω–∏—è:**
- **Regularization**: L1/L2, dropout
- **–ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö**: variance ‚àù 1/n
- **–£–ø—Ä–æ—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª—å**: –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **Early stopping**: –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –¥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
- **–ê–Ω—Å–∞–º–±–ª–∏**: bagging —Å–Ω–∏–∂–∞–µ—Ç variance

**–ü—Ä–æ–±–ª–µ–º–∞ 4: –ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—è (Underfitting)**

**–°–∏–º–ø—Ç–æ–º—ã:**
- Train error ‚âà Test error, –Ω–æ –æ–±–µ **–≤—ã—Å–æ–∫–∏–µ**
- –ú–æ–¥–µ–ª—å –Ω–µ —É–ª–∞–≤–ª–∏–≤–∞–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã

**High Bias —Å—Ü–µ–Ω–∞—Ä–∏–π:**
```python
Train MSE: 0.45
Test MSE:  0.47  ‚Üê –æ–±–µ –ø–ª–æ—Ö–∏–µ
```

**–†–µ—à–µ–Ω–∏—è:**
- **–£—Å–ª–æ–∂–Ω–∏—Ç—å –º–æ–¥–µ–ª—å**: polynomial features, –≥–ª—É–±–∂–µ —Å–µ—Ç—å
- **–ë–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**: feature engineering
- **–£–±—Ä–∞—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é**: —É–º–µ–Ω—å—à–∏—Ç—å Œª
- **–û–±—É—á–∞—Ç—å—Å—è –¥–æ–ª—å—à–µ**: –±–æ–ª—å—à–µ epochs

### 5) –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤ –∫ –±–∞–ª–∞–Ω—Å—É

| –ü–æ–¥—Ö–æ–¥ | –ö–∞–∫ –≤–ª–∏—è–µ—Ç –Ω–∞ Bias/Variance |
|--------|----------------------------|
| **Regularization (L2)** | Bias ‚Üë, Variance ‚Üì |
| **Feature selection** | Bias ‚Üë, Variance ‚Üì |
| **–ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö** | Bias ‚âà, Variance ‚Üì |
| **Bagging (Random Forest)** | Bias ‚âà, Variance ‚Üì‚Üì |
| **Boosting (XGBoost)** | Bias ‚Üì‚Üì, Variance ‚Üë (–Ω–æ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç—Å—è) |

---

## 1.4 –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è (Cross-Validation)

### 1) –ò–Ω—Ç—É–∏—Ü–∏—è –∏ —Å—É—Ç—å

**–ü—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ (ELI5):**  
–ü—Ä–µ–¥—Å—Ç–∞–≤—å, —á—Ç–æ —É —Ç–µ–±—è –µ—Å—Ç—å —ç–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã. –í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞—Ç—å—Å—è –Ω–∞ –æ–¥–Ω–æ–º –Ω–∞–±–æ—Ä–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –ø–æ—Ç–æ–º –ø—Ä–æ–≤–∞–ª–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π —ç–∫–∑–∞–º–µ–Ω (–ø–æ—Ç–æ–º—É —á—Ç–æ –≤–æ–ø—Ä–æ—Å—ã –¥—Ä—É–≥–∏–µ), —Ç—ã –¥–µ–ª–∏—à—å –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ —á–∞—Å—Ç–∏ –∏ —Ç—Ä–µ–Ω–∏—Ä—É–µ—à—å—Å—è –Ω–∞ –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏, –ø—Ä–æ–≤–µ—Ä—è—è—Å—å –Ω–∞ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö. –¢–∞–∫ —Ç—ã —Ç–æ—á–Ω–µ–µ –æ—Ü–µ–Ω–∏—à—å —Å–≤–æ—é —Ä–µ–∞–ª—å–Ω—É—é –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É.

**–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏:**  
–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è ‚Äî —ç—Ç–æ **—Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ç–µ—Ö–Ω–∏–∫–∞** –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –ø—É—Ç–µ–º —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ–ª–¥–æ–≤ (—á–∞—Å—Ç–µ–π). –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ k-1 —Ñ–æ–ª–¥–∞—Ö –∏ —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –æ—Å—Ç–∞–≤—à–µ–º—Å—è, –ø—Ä–æ—Ü–µ—Å—Å –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è k —Ä–∞–∑. –ò—Ç–æ–≥–æ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞ ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –≤—Å–µ–º —Ñ–æ–ª–¥–∞–º.

**–§–∏–∑–∏—á–µ—Å–∫–∏–π —Å–º—ã—Å–ª:**  
–ú—ã **—Å–∏–º—É–ª–∏—Ä—É–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ train/test —Ä–∞–∑–±–∏–µ–Ω–∏—è**, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—É—é –æ—Ü–µ–Ω–∫—É –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –∏ —Å–Ω–∏–∑–∏—Ç—å –≤–ª–∏—è–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏ –≤ —Ä–∞–∑–±–∏–µ–Ω–∏–∏.

### 2) –ó–∞—á–µ–º –∏ –∫–æ–≥–¥–∞ (Business Value)

**–ö–∞–∫—É—é –ø—Ä–æ–±–ª–µ–º—É —Ä–µ—à–∞–µ—Ç:**
- **–ù–∞–¥–µ–∂–Ω–∞—è –æ—Ü–µ–Ω–∫–∞** –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ (–º–µ–Ω—å—à–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è)
- **–ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤** (GridSearch, RandomSearch)
- **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π** –Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö
- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö** (–æ—Å–æ–±–µ–Ω–Ω–æ –ø—Ä–∏ –º–∞–ª—ã—Ö –≤—ã–±–æ—Ä–∫–∞—Ö)

**–ì–¥–µ —ç—Ç–æ –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç:**
- **AutoML —Å–∏—Å—Ç–µ–º—ã**: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **–ú–µ–¥–∏—Ü–∏–Ω–∞**: –º–∞–ª—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã, –≤–∞–∂–Ω–∞ —Ç–æ—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
- **–§–∏–Ω–∞–Ω—Å—ã**: –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã (Time Series CV)
- **Kaggle competitions**: –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π

**–ö–æ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å –Ω–µ–ª—å–∑—è:**
- ‚ùå –û—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ (–≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ –¥–æ—Ä–æ–≥–æ ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ hold-out)
- ‚ùå –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã —Å –ø—Ä–æ—Å—Ç—ã–º k-fold (–Ω–∞—Ä—É—à–∞–µ—Ç—Å—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–æ—Ä—è–¥–æ–∫ ‚Üí Time Series CV)
- ‚ùå –°–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ —Å –ø—Ä–æ—Å—Ç—ã–º k-fold ‚Üí Stratified CV

### 3) –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —è–¥—Ä–æ

**k-Fold Cross-Validation:**

1. –†–∞–∑–±–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ k —Ä–∞–≤–Ω—ã—Ö —á–∞—Å—Ç–µ–π (—Ñ–æ–ª–¥–æ–≤)
2. –î–ª—è i = 1 –¥–æ k:
   - –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —Ñ–æ–ª–¥–∞—Ö {1, ..., k} \ {i}
   - –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —Ñ–æ–ª–¥–µ i
   - –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫—É score_i
3. –ò—Ç–æ–≥–æ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞:
```
CV_score = (1/k) Œ£ score_i
```

**–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ:**
```
œÉ_CV = ‚àö[(1/k) Œ£ (score_i - CV_score)¬≤]
```
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç **—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å** –º–æ–¥–µ–ª–∏.

**Leave-One-Out CV (LOOCV):**

–ß–∞—Å—Ç–Ω—ã–π —Å–ª—É—á–∞–π k-fold, –≥–¥–µ k = n (—Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞).
- –û–±—É—á–∞–µ–º—Å—è –Ω–∞ n-1 –ø—Ä–∏–º–µ—Ä–∞—Ö, —Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ 1
- –ü–æ–≤—Ç–æ—Ä—è–µ–º n —Ä–∞–∑

**–§–æ—Ä–º—É–ª–∞:**
```
CV_LOOCV = (1/n) Œ£ L(y_i, ≈∑_{-i})
```
–≥–¥–µ ≈∑_{-i} ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–Ω–æ–π –±–µ–∑ i-–≥–æ –ø—Ä–∏–º–µ—Ä–∞.

### 4) Middle-level –Ω—é–∞–Ω—Å—ã

**–ü—Ä–æ–±–ª–µ–º–∞ 1: –í—ã–±–æ—Ä k (–≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä CV)**

| k | –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ | –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ |
|---|-------------|-----------|
| **k=5** | ‚úÖ –ë—ã—Å—Ç—Ä–æ<br>‚úÖ –ë–∞–ª–∞–Ω—Å bias/variance | ‚ö†Ô∏è –ú–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ |
| **k=10** | ‚úÖ –°—Ç–∞–Ω–¥–∞—Ä—Ç<br>‚úÖ –•–æ—Ä–æ—à–∞—è –æ—Ü–µ–Ω–∫–∞ | –î–æ–ª—å—à–µ, —á–µ–º k=5 |
| **k=n (LOOCV)** | ‚úÖ –ú–∞–∫—Å–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è<br>‚úÖ –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ | ‚ùå –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ<br>‚ùå High variance –æ—Ü–µ–Ω–∫–∏ |

**–≠–º–ø–∏—Ä–∏—á–µ—Å–∫–æ–µ –ø—Ä–∞–≤–∏–ª–æ:**  
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ **k=10** –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é. –î–ª—è –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö (n < 100) ‚Üí k=5 –∏–ª–∏ LOOCV.

**–ü—Ä–æ–±–ª–µ–º–∞ 2: Stratified k-Fold (–¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤)**

**–ü—Ä–æ–±–ª–µ–º–∞ –æ–±—ã—á–Ω–æ–≥–æ k-fold:**  
–ü—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 5% –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö) —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –º–æ–∂–µ—Ç –¥–∞—Ç—å —Ñ–æ–ª–¥ –±–µ–∑ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤–æ–æ–±—â–µ!

**–†–µ—à–µ–Ω–∏–µ ‚Äî Stratified:**  
–í –∫–∞–∂–¥–æ–º —Ñ–æ–ª–¥–µ **—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ø—Ä–æ–ø–æ—Ä—Ü–∏—è –∫–ª–∞—Å—Å–æ–≤** –∫–∞–∫ –≤ –∏—Å—Ö–æ–¥–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ.

**–ü—Ä–∏–º–µ—Ä:**
```
Dataset: 100 –ø—Ä–∏–º–µ—Ä–æ–≤, 90 –∫–ª–∞—Å—Å 0, 10 –∫–ª–∞—Å—Å 1 (10% class 1)

k=5 Stratified:
  Fold 1: 18 –∫–ª–∞—Å—Å 0, 2 –∫–ª–∞—Å—Å 1 (10%)
  Fold 2: 18 –∫–ª–∞—Å—Å 0, 2 –∫–ª–∞—Å—Å 1 (10%)
  ...
  Fold 5: 18 –∫–ª–∞—Å—Å 0, 2 –∫–ª–∞—Å—Å 1 (10%)
```

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å **–¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º –∫–ª–∞—Å—Å–æ–≤**
- –ú–∞–ª—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã

**–ü—Ä–æ–±–ª–µ–º–∞ 3: Time Series Cross-Validation**

**–ü—Ä–æ–±–ª–µ–º–∞ –æ–±—ã—á–Ω–æ–≥–æ k-fold –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤:**  
–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –±—É–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö, —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø—Ä–æ—à–ª—ã—Ö ‚Üí **data leakage**!

**–†–µ—à–µ–Ω–∏–µ ‚Äî Time Series Split:**

```
Fold 1: Train [1..100],   Test [101..120]
Fold 2: Train [1..120],   Test [121..140]
Fold 3: Train [1..140],   Test [141..160]
...
```

**–°–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ (Sliding Window):**

```
Fold 1: Train [1..100],   Test [101..120]
Fold 2: Train [21..120],  Test [121..140]
Fold 3: Train [41..140],  Test [141..160]
```

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- **–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã**: —Ü–µ–Ω—ã –∞–∫—Ü–∏–π, —Å–ø—Ä–æ—Å, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
- **–î–∞–Ω–Ω—ã–µ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π**: –ª–æ–≥–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

**–ü—Ä–æ–±–ª–µ–º–∞ 4: Data Leakage —á–µ—Ä–µ–∑ preprocessing**

**–ù–ï–ü–†–ê–í–ò–õ–¨–ù–û:**
```python
# –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ, –ø–æ—Ç–æ–º –¥–µ–ª–∏–º
X_scaled = scaler.fit_transform(X)  # ‚Üê leakage!
cross_val_score(model, X_scaled, y, cv=5)
```

Scaler "–≤–∏–¥–µ–ª" —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–æ–ª–¥—ã ‚Üí –∑–∞–≤—ã—à–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞.

**–ü–†–ê–í–ò–õ–¨–ù–û:**
```python
# –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–æ–ª–¥–∞
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', LogisticRegression())
])
cross_val_score(pipeline, X, y, cv=5)  # ‚úÖ
```

Scaler –æ–±—É—á–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ train —Ñ–æ–ª–¥–∞—Ö –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏.

### 5) –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏

| –ú–µ—Ç–æ–¥ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å | –ü–ª—é—Å—ã | –ú–∏–Ω—É—Å—ã |
|-------|-------------------|-------|--------|
| **Hold-out (train/test)** | –ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ, –±—ã—Å—Ç—Ä—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç | ‚úÖ –ë—ã—Å—Ç—Ä–æ | ‚ùå –í—ã—Å–æ–∫–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è –æ—Ü–µ–Ω–∫–∏ |
| **k-Fold CV** | –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∑–∞–¥–∞—á–∞, —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö | ‚úÖ –ù–∞–¥–µ–∂–Ω–∞—è –æ—Ü–µ–Ω–∫–∞<br>‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ | ‚ùå k —Ä–∞–∑ –º–µ–¥–ª–µ–Ω–Ω–µ–µ |
| **Stratified k-Fold** | –î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ | ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ | –¢–æ–ª—å–∫–æ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ |
| **Time Series CV** | –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã | ‚úÖ –ù–µ—Ç data leakage | ‚ùå –ú–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ä–∞–Ω–Ω–∏—Ö —Ñ–æ–ª–¥–∞—Ö |
| **LOOCV** | –û—á–µ–Ω—å –º–∞–ª—ã–µ –¥–∞–Ω–Ω—ã–µ (n < 50) | ‚úÖ –ú–∞–∫—Å–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è | ‚ùå –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ<br>‚ùå High variance |

---

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã

1. **–í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ CV** –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –∞ –Ω–µ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ (–¥–ª—è –Ω–µ–µ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–π hold-out test set)

2. **–í–ª–æ–∂–µ–Ω–Ω–∞—è CV** (Nested CV) –¥–ª—è **–æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –æ—Ü–µ–Ω–∫–∏**:
   - –í–Ω–µ—à–Ω—è—è CV: –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
   - –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è CV: –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

3. **–î–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤** –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Time Series CV

4. **–î–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Stratified CV + —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ (F1, AUC-ROC)

5. **Pipeline** –≤ sklearn –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π preprocessing –≤ CV

---

## üìù –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–¥ (sklearn)

### k-NN: –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä —Å hyperparameters

```python
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–´ k-NN
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# n_neighbors (k): —á–∏—Å–ª–æ —Å–æ—Å–µ–¥–µ–π
#   - –ú–∞–ª—ã–π k (1-3): –≤—ã—Å–æ–∫–∏–π variance, —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —à—É–º—É
#   - –ë–æ–ª—å—à–æ–π k (10+): –≤—ã—Å–æ–∫–∏–π bias, —Å–≥–ª–∞–∂–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã
#   - –≠–º–ø–∏—Ä–∏–∫–∞: –Ω–∞—á–Ω–∏—Ç–µ —Å sqrt(n), –∑–∞—Ç–µ–º CV
#
# weights: –∫–∞–∫ –≤–∑–≤–µ—à–∏–≤–∞—Ç—å —Å–æ—Å–µ–¥–µ–π
#   - 'uniform': –≤—Å–µ —Å–æ—Å–µ–¥–∏ —Ä–∞–≤–Ω—ã
#   - 'distance': –±–ª–∏–∂–Ω–∏–µ —Å–æ—Å–µ–¥–∏ –≤–∞–∂–Ω–µ–µ (1/distance)
#
# metric: –º–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
#   - 'euclidean': —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
#   - 'manhattan': —É—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º
#   - 'minkowski' —Å p=1 (manhattan) –∏–ª–∏ p=2 (euclidean)
#
# algorithm: –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ —Å–æ—Å–µ–¥–µ–π
#   - 'auto': –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä
#   - 'ball_tree', 'kd_tree': –±—ã—Å—Ç—Ä–µ–µ –ø—Ä–∏ n >> k, d < 20
#   - 'brute': O(n*d), –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ —Ç–æ—á–Ω—ã–π
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Pipeline: –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ö–†–ò–¢–ò–ß–ù–û –¥–ª—è k-NN!
pipeline = Pipeline([
    ('scaler', StandardScaler()),  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–¥ k-NN
    ('knn', KNeighborsClassifier())
])

# GridSearch –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ k –∏ weights
param_grid = {
    'knn__n_neighbors': [3, 5, 7, 9, 11],
    'knn__weights': ['uniform', 'distance'],
    'knn__metric': ['euclidean', 'manhattan']
}

grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

print(f"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_search.best_params_}")
print(f"CV Accuracy: {grid_search.best_score_:.3f}")
```

### OLS: –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ vs sklearn

```python
from sklearn.linear_model import LinearRegression
import numpy as np

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–´ LinearRegression (sklearn)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# fit_intercept: –¥–æ–±–∞–≤–ª—è—Ç—å –ª–∏ bias term (b –≤ y = Xw + b)
#   - True (default): –¥–∞, –ø–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞ –Ω—É–∂–µ–Ω
#   - False: –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —É–∂–µ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã
#
# normalize: —É—Å—Ç–∞—Ä–µ–ª–æ! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ StandardScaler –≤ Pipeline
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# –°–ø–æ—Å–æ–± 1: sklearn LinearRegression
model = LinearRegression(fit_intercept=True)
model.fit(X_train, y_train)
print(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã: {model.coef_}")
print(f"Intercept: {model.intercept_}")

# –°–ø–æ—Å–æ–± 2: –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Ä—É—á–Ω—É—é (–¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è)
X_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]  # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü –µ–¥–∏–Ω–∏—Ü
theta = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y_train
print(f"Theta (–≤—Ä—É—á–Ω—É—é): {theta}")

# –°–ø–æ—Å–æ–± 3: np.linalg.lstsq (—á–∏—Å–ª–µ–Ω–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ)
theta_stable, residuals, rank, s = np.linalg.lstsq(X_b, y_train, rcond=None)
```

### Cross-Validation: –≤—Å–µ –≤–∏–¥—ã

```python
from sklearn.model_selection import (
    cross_val_score, KFold, StratifiedKFold, 
    TimeSeriesSplit, LeaveOneOut, GridSearchCV
)
from sklearn.pipeline import Pipeline

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –¢–ò–ü–´ CROSS-VALIDATION
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# 1. –ü—Ä–æ—Å—Ç–æ–π k-Fold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=kfold, scoring='r2')
print(f"k-Fold R¬≤: {scores.mean():.3f} ¬± {scores.std():.3f}")

# 2. Stratified k-Fold (–¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º)
stratified = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(classifier, X, y, cv=stratified, scoring='f1')

# 3. Time Series Split (–¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤)
tscv = TimeSeriesSplit(n_splits=5)
for train_idx, test_idx in tscv.split(X):
    print(f"Train: {train_idx[0]}-{train_idx[-1]}, Test: {test_idx[0]}-{test_idx[-1]}")

# 4. LOOCV (–¥–ª—è –æ—á–µ–Ω—å –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
loo = LeaveOneOut()  # n_splits = len(X)
scores = cross_val_score(model, X, y, cv=loo)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ü–†–ê–í–ò–õ–¨–ù–´–ô PIPELINE (–∏–∑–±–µ–≥–∞–µ–º data leakage!)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

pipeline = Pipeline([
    ('scaler', StandardScaler()),      # Fit —Ç–æ–ª—å–∫–æ –Ω–∞ train fold!
    ('model', LogisticRegression())
])

# CV –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ fit scaler —Ç–æ–ª—å–∫–æ –Ω–∞ train —á–∞—Å—Ç–∏ –∫–∞–∂–¥–æ–≥–æ fold
scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')
```

### –¢–∞–±–ª–∏—Ü–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

| –ú–æ–¥–µ–ª—å | –ü–∞—Ä–∞–º–µ—Ç—Ä | Default | –î–∏–∞–ø–∞–∑–æ–Ω | –ö–æ–≥–¥–∞ –º–µ–Ω—è—Ç—å |
|--------|----------|---------|----------|--------------|
| **k-NN** | n_neighbors | 5 | 1-‚àön | –í—Å–µ–≥–¥–∞ —á–µ—Ä–µ–∑ CV |
| | weights | uniform | uniform, distance | distance –ø—Ä–∏ –Ω–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–π –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ |
| | metric | minkowski | euclidean, manhattan | manhattan –ø—Ä–∏ –≤—ã–±—Ä–æ—Å–∞—Ö |
| **LinearReg** | fit_intercept | True | True/False | False –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã |
| **CV** | n_splits | 5 | 5-10 | 10 –¥–ª—è —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏, 5 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ |
| | shuffle | True | True/False | False –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤! |

---

## üéØ Q&A –¥–ª—è —ç–∫–∑–∞–º–µ–Ω–∞

**Q1: –ü–æ—á–µ–º—É k-NN —Å—Ç—Ä–∞–¥–∞–µ—Ç –æ—Ç –ø—Ä–æ–∫–ª—è—Ç–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏?**
> –ü—Ä–∏ —Ä–æ—Å—Ç–µ d –≤—Å–µ —Ç–æ—á–∫–∏ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤–æ –¥–∞–ª–µ–∫–∏ –¥—Ä—É–≥ –æ—Ç –¥—Ä—É–≥–∞ (–æ–±—ä–µ–º –≥–∏–ø–µ—Ä–∫—É–±–∞ —Ä–∞—Å—Ç–µ—Ç –∫–∞–∫ L^d). –ü–æ–Ω—è—Ç–∏–µ "–±–ª–∏–∂–∞–π—à–∏–π —Å–æ—Å–µ–¥" —Ç–µ—Ä—è–µ—Ç —Å–º—ã—Å–ª ‚Äî –Ω—É–∂–Ω–æ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ–π –∂–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏.

**Q2: –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ vs –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫?**
> –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ: p < 10,000 (O(p¬≥) —Å–ª–æ–∂–Ω–æ—Å—Ç—å). –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫: –±–æ–ª—å—à–æ–µ p, –æ–Ω–ª–∞–π–Ω-–æ–±—É—á–µ–Ω–∏–µ, —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è. –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ sklearn –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º.

**Q3: –ö–∞–∫ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å high bias vs high variance –Ω–∞ learning curves?**
> High bias: train –∏ test –æ—à–∏–±–∫–∏ —Å—Ö–æ–¥—è—Ç—Å—è –∫ –≤—ã—Å–æ–∫–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é (–æ–±–µ –ø–ª–æ—Ö–∏–µ). High variance: train –æ—à–∏–±–∫–∞ –Ω–∏–∑–∫–∞—è, test –≤—ã—Å–æ–∫–∞—è (–±–æ–ª—å—à–æ–π —Ä–∞–∑—Ä—ã–≤). –†–µ—à–µ–Ω–∏–µ: —É—Å–ª–æ–∂–Ω–∏—Ç—å –º–æ–¥–µ–ª—å (bias) –∏–ª–∏ –¥–æ–±–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ/—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é (variance).

**Q4: –ü–æ—á–µ–º—É Stratified CV –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ –∫–ª–∞—Å—Å–æ–≤?**
> –ü—Ä–∏ —Å–ª—É—á–∞–π–Ω–æ–º —Ä–∞–∑–±–∏–µ–Ω–∏–∏ —Ñ–æ–ª–¥ –º–æ–∂–µ—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø—Ä–∏–º–µ—Ä–æ–≤ —Ä–µ–¥–∫–æ–≥–æ –∫–ª–∞—Å—Å–∞ –≤–æ–æ–±—â–µ! Stratified —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –∫–ª–∞—Å—Å–æ–≤ –≤ –∫–∞–∂–¥–æ–º —Ñ–æ–ª–¥–µ.

**Q5: –ß—Ç–æ —Ç–∞–∫–æ–µ data leakage –ø—Ä–∏ preprocessing –≤ CV?**
> –ï—Å–ª–∏ scaler.fit() –ø—Ä–∏–º–µ–Ω–µ–Ω –∫–æ –í–°–ï–ú –¥–∞–Ω–Ω—ã–º –¥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —Ñ–æ–ª–¥—ã, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (mean, std) –≤–∫–ª—é—á–∞—é—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ test —Ñ–æ–ª–¥–∞ ‚Üí –∑–∞–≤—ã—à–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞. –†–µ—à–µ–Ω–∏–µ: Pipeline –≤ sklearn –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ fit scaler —Ç–æ–ª—å–∫–æ –Ω–∞ train —á–∞—Å—Ç–∏ –∫–∞–∂–¥–æ–≥–æ —Ñ–æ–ª–¥–∞.

---

## –†–µ–∑—é–º–µ –º–æ–¥—É–ª—è

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –∑–∞–ª–æ–∂–∏–ª **—Ñ—É–Ω–¥–∞–º–µ–Ω—Ç ML**:
- **k-NN**: –ø—Ä–æ—Å—Ç–æ—Ç–∞ –∏ –º–æ—â—å –ª–æ–∫–∞–ª—å–Ω–æ—Å—Ç–∏, –±–æ—Ä—å–±–∞ —Å –ø—Ä–æ–∫–ª—è—Ç–∏–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
- **OLS**: –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è, –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ, –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å
- **Bias-Variance**: –∫–ª—é—á–µ–≤–æ–π trade-off, –æ–±—ä—è—Å–Ω—è—é—â–∏–π –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
- **Cross-Validation**: –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π –∏ –∑–∞—â–∏—Ç–∞ –æ—Ç overfitting

–≠—Ç–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ ‚Äî –æ—Å–Ω–æ–≤–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤—Å–µ—Ö –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –º–µ—Ç–æ–¥–æ–≤ ML.
