{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<h1 style=\"text-align: center;\">Assignment 7: Energy Efficiency Dataset üè¢‚ö°</h1>\n",
                "\n",
                "<p style=\"text-align: center;\">Predicting Heating Load from Building Features</p>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q1: Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (10, 6)\n",
                "\n",
                "# Read Excel file\n",
                "df = pd.read_excel('ENB2012_data.xlsx')\n",
                "\n",
                "# Rename columns\n",
                "columns = ['Relative_Compactness', 'Surface_Area', 'Wall_Area', 'Roof_Area',\n",
                "           'Overall_Height', 'Orientation', 'Glazing_Area', 'Glazing_Area_Distribution',\n",
                "           'Heating_Load', 'Cooling_Load']\n",
                "df.columns = columns\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q2: Dataset Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Dataset Info:\")\n",
                "print(f\"Rows: {len(df)}\")\n",
                "print(f\"Columns: {len(df.columns)}\")\n",
                "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
                "print(f\"\\nBasic statistics:\")\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q3: Feature Distributions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(4, 3, figsize=(15, 12))\n",
                "axes = axes.ravel()\n",
                "\n",
                "for idx, col in enumerate(df.columns):\n",
                "    axes[idx].hist(df[col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
                "    axes[idx].set_title(f'{col}')\n",
                "    axes[idx].set_xlabel(col)\n",
                "    axes[idx].set_ylabel('Frequency')\n",
                "\n",
                "for idx in range(len(df.columns), len(axes)):\n",
                "    axes[idx].set_visible(False)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observations:**\n",
                "- Orientation and Glazing_Area_Distribution are categorical\n",
                "- Overall_Height has only 2 values\n",
                "- Surface/Wall/Roof areas show multiple peaks"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q4: Unique Values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Unique values per feature:\")\n",
                "for col in df.columns:\n",
                "    print(f\"{col:30s}: {df[col].nunique():3d}\")\n",
                "\n",
                "print(\"\\nCategorical features:\")\n",
                "for col in ['Orientation', 'Glazing_Area_Distribution', 'Overall_Height']:\n",
                "    print(f\"\\n{col}:\")\n",
                "    print(df[col].value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q4.1: Duplicates"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "n_duplicates = df.duplicated().sum()\n",
                "print(f\"Duplicate rows: {n_duplicates}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q5: Correlation with Target"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "correlations = df.corr()['Heating_Load'].drop('Heating_Load').sort_values(ascending=False)\n",
                "\n",
                "print(\"Correlations with Heating_Load:\")\n",
                "print(correlations)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "correlations.plot(kind='barh', color='steelblue')\n",
                "plt.title('Feature Correlation with Heating Load')\n",
                "plt.xlabel('Correlation')\n",
                "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n‚ö†Ô∏è WARNING: Cooling_Load has high correlation (0.976)\")\n",
                "print(\"This is DATA LEAKAGE - must remove it!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q6: Scatter Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pandas.plotting import scatter_matrix\n",
                "\n",
                "# Select weak correlations\n",
                "weak_features = correlations[abs(correlations) < 0.5].index.tolist()\n",
                "features_to_plot = weak_features + ['Heating_Load']\n",
                "\n",
                "print(f\"Weak correlation features: {weak_features}\")\n",
                "\n",
                "scatter_matrix(df[features_to_plot], figsize=(12, 10), alpha=0.6, diagonal='hist')\n",
                "plt.suptitle('Scatter Matrix: Weak Correlations', y=1.0)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q7: Custom Transformer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.base import BaseEstimator, TransformerMixin\n",
                "\n",
                "class RatioTransformer(BaseEstimator, TransformerMixin):\n",
                "    \"\"\"Creates ratio features from column pairs\"\"\"\n",
                "    \n",
                "    def __init__(self, ratio_pairs):\n",
                "        # ratio_pairs = [(num_col, denom_col, new_col_name), ...]\n",
                "        self.ratio_pairs = ratio_pairs\n",
                "    \n",
                "    def fit(self, X, y=None):\n",
                "        return self\n",
                "    \n",
                "    def transform(self, X):\n",
                "        X_copy = X.copy()\n",
                "        for num_col, denom_col, new_col in self.ratio_pairs:\n",
                "            # +1e-10 prevents division by zero\n",
                "            X_copy[new_col] = X_copy[num_col] / (X_copy[denom_col] + 1e-10)\n",
                "        return X_copy\n",
                "\n",
                "# Test\n",
                "ratio_transformer = RatioTransformer([('Wall_Area', 'Surface_Area', 'Wall_to_Surface_Ratio')])\n",
                "test_df = ratio_transformer.fit_transform(df.head())\n",
                "print(\"New feature created:\")\n",
                "print(test_df[['Wall_Area', 'Surface_Area', 'Wall_to_Surface_Ratio']].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q8: Preprocessing Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                "\n",
                "# Define feature groups\n",
                "categorical_features = ['Orientation', 'Glazing_Area_Distribution']\n",
                "numerical_features = ['Relative_Compactness', 'Surface_Area', 'Wall_Area', 'Roof_Area',\n",
                "                      'Overall_Height', 'Glazing_Area']\n",
                "\n",
                "# Create pipeline\n",
                "preprocessor = ColumnTransformer([\n",
                "    ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features),  # drop='first' avoids multicollinearity\n",
                "    ('num', StandardScaler(), numerical_features)  # Mean=0, Std=1\n",
                "], remainder='drop')\n",
                "\n",
                "print(\"Pipeline created!\")\n",
                "print(f\"Categorical: {categorical_features}\")\n",
                "print(f\"Numerical: {numerical_features}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q9: Train/Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Remove both targets (avoid data leakage!)\n",
                "X = df.drop(['Heating_Load', 'Cooling_Load'], axis=1)\n",
                "y = df['Heating_Load']\n",
                "\n",
                "# Split: 80% train, 20% test, random_state=42 for reproducibility\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(f\"Training: {len(X_train)} samples\")\n",
                "print(f\"Test: {len(X_test)} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q10: Apply Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit on train only (no data leakage!)\n",
                "X_train_processed = preprocessor.fit_transform(X_train)\n",
                "X_test_processed = preprocessor.transform(X_test)\n",
                "\n",
                "print(f\"Processed train shape: {X_train_processed.shape}\")\n",
                "print(f\"Processed test shape: {X_test_processed.shape}\")\n",
                "print(f\"Total features: {X_train_processed.shape[1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q11: Linear Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "\n",
                "# Train model\n",
                "lr_model = LinearRegression()\n",
                "lr_model.fit(X_train_processed, y_train)\n",
                "\n",
                "# Predict\n",
                "y_pred_lr = lr_model.predict(X_test_processed)\n",
                "\n",
                "# Evaluate\n",
                "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
                "r2_lr = r2_score(y_test, y_pred_lr)\n",
                "\n",
                "print(\"Linear Regression Results:\")\n",
                "print(f\"RMSE: {rmse_lr:.4f}\")\n",
                "print(f\"R¬≤ Score: {r2_lr:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q12: Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import RandomForestRegressor\n",
                "\n",
                "# n_estimators=200: number of trees\n",
                "# random_state=42: reproducibility\n",
                "# n_jobs=-1: use all CPU cores\n",
                "rf_model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
                "rf_model.fit(X_train_processed, y_train)\n",
                "\n",
                "y_pred_rf = rf_model.predict(X_test_processed)\n",
                "\n",
                "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
                "r2_rf = r2_score(y_test, y_pred_rf)\n",
                "\n",
                "print(\"Random Forest Results:\")\n",
                "print(f\"RMSE: {rmse_rf:.4f}\")\n",
                "print(f\"R¬≤ Score: {r2_rf:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q13: Gradient Boosting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import GradientBoostingRegressor\n",
                "\n",
                "# n_estimators=200: number of boosting rounds\n",
                "# learning_rate default=0.1: step size\n",
                "gb_model = GradientBoostingRegressor(n_estimators=200, random_state=42)\n",
                "gb_model.fit(X_train_processed, y_train)\n",
                "\n",
                "y_pred_gb = gb_model.predict(X_test_processed)\n",
                "\n",
                "rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))\n",
                "r2_gb = r2_score(y_test, y_pred_gb)\n",
                "\n",
                "print(\"Gradient Boosting Results:\")\n",
                "print(f\"RMSE: {rmse_gb:.4f}\")\n",
                "print(f\"R¬≤ Score: {r2_gb:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Q14: Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comparison table\n",
                "results = pd.DataFrame({\n",
                "    'Model': ['Linear Regression', 'Random Forest', 'Gradient Boosting'],\n",
                "    'RMSE': [rmse_lr, rmse_rf, rmse_gb],\n",
                "    'R¬≤ Score': [r2_lr, r2_rf, r2_gb]\n",
                "})\n",
                "\n",
                "results = results.sort_values('R¬≤ Score', ascending=False).reset_index(drop=True)\n",
                "print(\"Model Comparison:\")\n",
                "print(results.to_string(index=False))\n",
                "\n",
                "# Visualize\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# RMSE (lower is better)\n",
                "axes[0].bar(results['Model'], results['RMSE'], color=['steelblue', 'forestgreen', 'coral'])\n",
                "axes[0].set_ylabel('RMSE (lower = better)')\n",
                "axes[0].set_title('RMSE Comparison')\n",
                "axes[0].tick_params(axis='x', rotation=15)\n",
                "\n",
                "# R¬≤ (higher is better)\n",
                "axes[1].bar(results['Model'], results['R¬≤ Score'], color=['steelblue', 'forestgreen', 'coral'])\n",
                "axes[1].set_ylabel('R¬≤ Score (higher = better)')\n",
                "axes[1].set_title('R¬≤ Comparison')\n",
                "axes[1].tick_params(axis='x', rotation=15)\n",
                "axes[1].axhline(y=0.9, color='red', linestyle='--', label='Excellent (0.9)')\n",
                "axes[1].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## R¬≤ Metric Explanation\n",
                "\n",
                "**R¬≤ (Coefficient of Determination)** measures how well the model explains data variance.\n",
                "\n",
                "**Range**: 0 to 1 (can be negative for very bad models)\n",
                "\n",
                "**Interpretation**:\n",
                "- **R¬≤ = 1.0**: Perfect predictions (100% variance explained)\n",
                "- **R¬≤ = 0.9**: Excellent (90% variance explained)\n",
                "- **R¬≤ = 0.5**: Moderate (50% variance explained)\n",
                "- **R¬≤ = 0.0**: No better than predicting the average\n",
                "\n",
                "**Why tree models win**:\n",
                "- Building features have **non-linear** relationships\n",
                "- Complex interactions between shape, area, and glazing\n",
                "- Linear Regression assumes straight-line relationships\n",
                "- Random Forest and Gradient Boosting capture curves and interactions"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}