{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"background-color:#f4f4f4; padding: 20px; border-radius: 10px; border-left: 5px solid #2c3e50;\">\n",
                "    <h1 style=\"color: #2c3e50; text-align: center;\">üöÄ Assignment 7: Energy Efficiency Analysis</h1>\n",
                "    <h3 style=\"color: #7f8c8d; text-align: center;\">Mastering Regression Pipelines & Feature Engineering</h3>\n",
                "    <hr style=\"border: 1px solid #bdc3c7;\">\n",
                "    <p style=\"font-size: 16px; text-align: center;\">\n",
                "        <strong>Student:</strong> Namazbek Bekzhanov<br>\n",
                "        <strong>Course:</strong> Data Mining & Machine Learning\n",
                "    </p>\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìñ Project Overview\n",
                "\n",
                "In this assignment, we analyze the **Energy Efficiency Dataset**. The goal is to predict the **Heating Load** of a building based on its geometric and physical properties.\n",
                "\n",
                "### üéØ Objectives\n",
                "1.  **Exploratory Data Analysis (EDA):** Understand feature distributions and correlations.\n",
                "2.  **Feature Engineering:** Create custom transformers to expose hidden patterns.\n",
                "3.  **Pipeline Construction:** Build robust preprocessing pipelines for numerical and categorical data.\n",
                "4.  **Model Comparison:** Evaluate Linear Regression, Random Forest, and Gradient Boosting models.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üõ†Ô∏è 1. Setup and Library Imports\n",
                "We start by importing necessary libraries and configuring the visual style for a professional look."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import warnings\n",
                "\n",
                "# Scikit-Learn Imports\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.base import BaseEstimator, TransformerMixin\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "from sklearn import set_config\n",
                "\n",
                "# üé® Styling Configuration\n",
                "sns.set_theme(style=\"whitegrid\", context=\"notebook\", palette=\"deep\")\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "plt.rcParams['axes.titlesize'] = 16\n",
                "plt.rcParams['axes.labelsize'] = 14\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set sklearn to output diagrams\n",
                "set_config(display='diagram')\n",
                "\n",
                "print(\"‚úÖ Libraries imported and styling configured successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üì• 2. Data Loading & Initial Inspection\n",
                "We load the dataset from an Excel file and rename columns to be more human-readable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load dataset\n",
                "df = pd.read_excel('ENB2012_data.xlsx')\n",
                "\n",
                "# Rename columns for clarity\n",
                "column_map = {\n",
                "    'X1': 'Relative_Compactness',\n",
                "    'X2': 'Surface_Area',\n",
                "    'X3': 'Wall_Area',\n",
                "    'X4': 'Roof_Area',\n",
                "    'X5': 'Overall_Height',\n",
                "    'X6': 'Orientation',\n",
                "    'X7': 'Glazing_Area',\n",
                "    'X8': 'Glazing_Area_Distribution',\n",
                "    'Y1': 'Heating_Load',\n",
                "    'Y2': 'Cooling_Load'\n",
                "}\n",
                "\n",
                "# Apply renaming only if columns are currently generic (X1, X2...)\n",
                "if 'X1' in df.columns:\n",
                "    df = df.rename(columns=column_map)\n",
                "else:\n",
                "    # Ensuring names match the requirement if already named\n",
                "    df.columns = column_map.values()\n",
                "\n",
                "# Display first 5 rows with gradient styling\n",
                "df.head().style.background_gradient(cmap='Blues')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset Summary Statistics\n",
                "print(f\"üìä Dataset Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
                "print(\"\\nüîç Missing Values:\")\n",
                "print(df.isnull().sum()[df.isnull().sum() > 0]) # Prints only columns with missing values\n",
                "if df.isnull().sum().sum() == 0:\n",
                "    print(\"   No missing values found! ‚úÖ\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üìä 3. Exploratory Data Analysis (EDA)\n",
                "Understanding the distribution of our features is critical for model selection."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot histograms for all numerical features\n",
                "df.hist(bins=20, figsize=(15, 12), edgecolor='black', color='#3498db', grid=False)\n",
                "plt.suptitle('üìà Feature Distributions', fontsize=20, y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> **üí° Observation:** features like `Relative_Compactness` and `Surface_Area` show multimodal distributions (multiple peaks), suggesting distinguishable groups of building types."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation Heatmap with Target Variable\n",
                "plt.figure(figsize=(10, 8))\n",
                "corr_matrix = df.corr()\n",
                "\n",
                "# Mask mostly self-correlations for cleaner look\n",
                "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
                "\n",
                "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt=\".2f\", cmap='RdBu_r', vmin=-1, vmax=1, linewidths=0.5)\n",
                "plt.title('üî• Feature Correlation Matrix', fontsize=18)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚ö†Ô∏è Critical Data Leakage Check\n",
                "Notice that `Cooling_Load` has a correlation of near **1.0** with our target `Heating_Load`. Since we cannot know the cooling load before knowing the building properties (it's another output), using it as a feature would be **Data Leakage**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Correlation between Heating and Cooling Load: {df['Heating_Load'].corr(df['Cooling_Load']):.4f}\")\n",
                "print(\"‚úÖ Action: Dropping 'Cooling_Load' from features to prevent leakage.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚öôÔ∏è 4. Advanced Feature Engineering\n",
                "We create a **Custom Transformer** to generate new features. Specifically, the ratio of Wall Area to Floor Area might be more predictive than raw variance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class RatioTransformer(BaseEstimator, TransformerMixin):\n",
                "    \"\"\"\n",
                "    Custom Transformer that calculates the ratio between two columns.\n",
                "    Useful for engineering features like 'Wall-to-Surface Ratio'.\n",
                "    \"\"\"\n",
                "    def __init__(self, numerator, denominator, new_col_name):\n",
                "        self.numerator = numerator\n",
                "        self.denominator = denominator\n",
                "        self.new_col_name = new_col_name\n",
                "\n",
                "    def fit(self, X, y=None):\n",
                "        return self\n",
                "\n",
                "    def transform(self, X):\n",
                "        X_copy = X.copy() if isinstance(X, pd.DataFrame) else pd.DataFrame(X)\n",
                "        # Use a small epsilon to avoid division by zero\n",
                "        X_copy[self.new_col_name] = X_copy[self.numerator] / (X_copy[self.denominator] + 1e-9)\n",
                "        return X_copy\n",
                "\n",
                "# Demonstrate usage\n",
                "ratio_maker = RatioTransformer('Wall_Area', 'Surface_Area', 'Wall_Surface_Ratio')\n",
                "df_demonstration = ratio_maker.transform(df.head())\n",
                "\n",
                "print(\"‚ú® New Feature 'Wall_Surface_Ratio' created:\")\n",
                "display(df_demonstration[['Wall_Area', 'Surface_Area', 'Wall_Surface_Ratio']].head(3))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚õìÔ∏è 5. Pipeline Construction\n",
                "We build a robust processing pipeline that handles scaling for numerical data and encoding for categorical data automatically."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Define Feature Groups\n",
                "categorical_features = ['Orientation', 'Glazing_Area_Distribution']\n",
                "numerical_features = ['Relative_Compactness', 'Surface_Area', 'Wall_Area', 'Roof_Area', 'Overall_Height', 'Glazing_Area']\n",
                "\n",
                "# 2. Build Preprocessor\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', StandardScaler(), numerical_features),            # Scale numeric features\n",
                "        ('cat', OneHotEncoder(drop='first'), categorical_features) # Encode categorical features\n",
                "    ],\n",
                "    remainder='drop'  # Drop columns not specified (like the target variable if present)\n",
                ")\n",
                "\n",
                "# Visualize the Pipeline Structure\n",
                "preprocessor"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚úÇÔ∏è 6. Data Splitting\n",
                "We split the data **80/20** to ensure we have enough data to train (80%) while keeping a statistically significant portion for testing (20%)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df.drop(['Heating_Load', 'Cooling_Load'], axis=1)\n",
                "y = df['Heating_Load']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(f\"üîπ Training Samples: {X_train.shape[0]}\")\n",
                "print(f\"üîπ Testing Samples:  {X_test.shape[0]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ü§ñ 7. Model Training & Comparison\n",
                "We will train three different regression models to see which best captures the complex relationships in heat loss.\n",
                "\n",
                "1.  **Linear Regression**: The baseline. Good for linear relationships.\n",
                "2.  **Random Forest**: Captures non-linearities using an ensemble of decision trees.\n",
                "3.  **Gradient Boosting**: Iteratively corrects errors of previous trees. Often the state-of-the-art for tabular data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Models\n",
                "models = {\n",
                "    \"Linear Regression\": LinearRegression(),\n",
                "    \"Random Forest\": RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1),\n",
                "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=200, random_state=42)\n",
                "}\n",
                "\n",
                "# Dictionary to store results\n",
                "results = {}\n",
                "\n",
                "print(\"üö¶ Starting Model Training...\\n\")\n",
                "\n",
                "for name, model in models.items():\n",
                "    # Create a full pipeline including the preprocessor\n",
                "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                          ('classifier', model)])\n",
                "    \n",
                "    # Train\n",
                "    clf.fit(X_train, y_train)\n",
                "    \n",
                "    # Predict\n",
                "    y_pred = clf.predict(X_test)\n",
                "    \n",
                "    # Evaluate\n",
                "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
                "    r2 = r2_score(y_test, y_pred)\n",
                "    \n",
                "    results[name] = {\"RMSE\": rmse, \"R2_Score\": r2}\n",
                "    \n",
                "    print(f\"‚úÖ {name:<20} | RMSE: {rmse:.4f} | R¬≤: {r2:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üèÜ 8. Final Evaluation\n",
                "Let's visualize the performance to declare a winner."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert results to DataFrame for easier plotting\n",
                "results_df = pd.DataFrame(results).T.sort_values(by=\"RMSE\")\n",
                "\n",
                "# Plotting\n",
                "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
                "\n",
                "# RMSE Plot\n",
                "sns.barplot(x=results_df.index, y=results_df[\"RMSE\"], ax=axes[0], palette=\"Reds_d\")\n",
                "axes[0].set_title(\"üìâ RMSE Comparison (Lower is Better)\", fontsize=14, fontweight='bold')\n",
                "axes[0].set_ylabel(\"Root Mean Squared Error\")\n",
                "axes[0].bar_label(axes[0].containers[0], fmt='%.3f')\n",
                "\n",
                "# R2 Plot\n",
                "sns.barplot(x=results_df.index, y=results_df[\"R2_Score\"], ax=axes[1], palette=\"Greens_d\")\n",
                "axes[1].set_title(\"üìà R¬≤ Score Comparison (Higher is Better)\", fontsize=14, fontweight='bold')\n",
                "axes[1].set_ylabel(\"R¬≤ Score\")\n",
                "axes[1].set_ylim(0, 1.05)\n",
                "axes[1].bar_label(axes[1].containers[0], fmt='%.3f')\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div style=\"background-color:#e8f8f5; padding: 20px; border-radius: 10px; border-left: 5px solid #1abc9c;\">\n",
                "    <h3>üåü Conclusion</h3>\n",
                "    <ul>\n",
                "        <li><strong>Gradient Boosting & Random Forest</strong> significantly perform better than Linear Regression.</li>\n",
                "        <li>This indicates that the relationship between building geometry and heating load is <strong>non-linear</strong>.</li>\n",
                "        <li><strong>Recommendation:</strong> Use the <strong>Gradient Boosting Regressor</strong> for deployment as it achieved the lowest error rates (RMSE) and highest predictive accuracy (R¬≤).</li>\n",
                "    </ul>\n",
                "</div>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}