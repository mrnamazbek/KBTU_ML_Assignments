# üõ°Ô∏è Defense Guide: Assignment 5 (Adult Income)
# üá∑üá∫ –ì–∞–π–¥ –ø–æ –∑–∞—â–∏—Ç–µ: –ó–∞–¥–∞–Ω–∏–µ 5 (–î–æ—Ö–æ–¥—ã –≤–∑—Ä–æ—Å–ª—ã—Ö)

---

## üéØ Goal / –¶–µ–ª—å
**üá¨üáß English:**  
Predict if a person earns more than **$50k/year** based on census data (age, education, occupation, etc.). This is a **Binary Classification** task.

**üá∑üá∫ –†—É—Å—Å–∫–∏–π:**  
–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å, –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ª–∏ —á–µ–ª–æ–≤–µ–∫ –±–æ–ª—å—à–µ **$50k –≤ –≥–æ–¥**, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–ø–∏—Å–∏ (–≤–æ–∑—Ä–∞—Å—Ç, –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, –ø—Ä–æ—Ñ–µ—Å—Å–∏—è –∏ —Ç.–¥.). –≠—Ç–æ –∑–∞–¥–∞—á–∞ **–ë–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**.

---

## üß† Deep Code Analysis / –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞

### 1. Handling Missing Values / –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
```python
df.fillna(df.median(), inplace=True) # Numerical
df.fillna(df.mode()[0], inplace=True) # Categorical
```
*   **üá¨üáß Logic:** We cannot train models with empty data (NaN).
    *   **Numerical:** We use the **Median** because it is robust to outliers (unlike Mean).
    *   **Categorical:** We use the **Mode** (most frequent value).
*   **üá∑üá∫ –õ–æ–≥–∏–∫–∞:** –ú—ã –Ω–µ –º–æ–∂–µ–º –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö (NaN).
    *   **–ß–∏—Å–ª–æ–≤—ã–µ:** –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º **–ú–µ–¥–∏–∞–Ω—É**, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ —É—Å—Ç–æ–π—á–∏–≤–∞ –∫ –≤—ã–±—Ä–æ—Å–∞–º (–≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç –°—Ä–µ–¥–Ω–µ–≥–æ).
    *   **–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ:** –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º **–ú–æ–¥—É** (—Å–∞–º–æ–µ —á–∞—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ).

### 2. One-Hot Encoding / One-Hot –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
```python
pd.get_dummies(X, drop_first=True)
```
*   **üá¨üáß Logic:** Converts categorical text into numbers.
    *   "Male" -> `1`, "Female" -> `0`.
    *   `drop_first=True` removes the first column to avoid multicollinearity (Dummy Variable Trap). If we know it's not Male, it must be Female.
*   **üá∑üá∫ –õ–æ–≥–∏–∫–∞:** –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–∞.
    *   "Male" -> `1`, "Female" -> `0`.
    *   `drop_first=True` —É–¥–∞–ª—è–µ—Ç –ø–µ—Ä–≤—É—é –∫–æ–ª–æ–Ω–∫—É, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏ (–õ–æ–≤—É—à–∫–∞ —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö). –ï—Å–ª–∏ –º—ã –∑–Ω–∞–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –ú—É–∂—á–∏–Ω–∞, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –ñ–µ–Ω—â–∏–Ω–∞.

### 3. Logistic Regression / –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
```python
LogisticRegression(max_iter=1000)
```
*   **üá¨üáß Logic:** Predicts the **probability** (0 to 1) that a person belongs to the ">50k" class using a sigmoid function.
*   **üá∑üá∫ –õ–æ–≥–∏–∫–∞:** –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç **–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å** (–æ—Ç 0 –¥–æ 1), —á—Ç–æ —á–µ–ª–æ–≤–µ–∫ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –∫ –∫–ª–∞—Å—Å—É ">50k", –∏—Å–ø–æ–ª—å–∑—É—è —Å–∏–≥–º–æ–∏–¥–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é.

---

## üìâ Weak Points & Improvements / –°–ª–∞–±—ã–µ –º–µ—Å—Ç–∞ –∏ —É–ª—É—á—à–µ–Ω–∏—è

### 1. Missing Feature Scaling / –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
*   **üá¨üáß Weakness:** We did **not** scale the data. KNN is distance-based. "Capital Gain" (0-99999) dominates "Age" (0-100).
*   **üá∑üá∫ –°–ª–∞–±–æ—Å—Ç—å:** –ú—ã **–Ω–µ** –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–ª–∏ –¥–∞–Ω–Ω—ã–µ. KNN –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏. "–ü—Ä–∏—Ä–æ—Å—Ç –∫–∞–ø–∏—Ç–∞–ª–∞" (0-99999) –¥–æ–º–∏–Ω–∏—Ä—É–µ—Ç –Ω–∞–¥ "–í–æ–∑—Ä–∞—Å—Ç–æ–º" (0-100).
*   **üöÄ Improvement:** Apply **StandardScaler** or **MinMaxScaler** before training KNN. / –ü—Ä–∏–º–µ–Ω–∏—Ç—å **StandardScaler** –∏–ª–∏ **MinMaxScaler** –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º KNN.

### 2. Imbalanced Data / –ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
*   **üá¨üáß Weakness:** There are many more poor people (<=50k) than rich people (>50k). The model might be biased towards the majority class.
*   **üá∑üá∫ –°–ª–∞–±–æ—Å—Ç—å:** –ë–µ–¥–Ω—ã—Ö –ª—é–¥–µ–π (<=50k) –Ω–∞–º–Ω–æ–≥–æ –±–æ–ª—å—à–µ, —á–µ–º –±–æ–≥–∞—Ç—ã—Ö (>50k). –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–º–µ—â–µ–Ω–∞ –≤ —Å—Ç–æ—Ä–æ–Ω—É –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞.
*   **üöÄ Improvement:** Use `class_weight='balanced'` in Logistic Regression. / –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `class_weight='balanced'` –≤ –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.

---

## ‚ùì Professor Questions / –í–æ–ø—Ä–æ—Å—ã –ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä–∞

### Q1: Why use `drop_first=True` in One-Hot Encoding?
### –í1: –ó–∞—á–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `drop_first=True` –≤ One-Hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏?
*   **üá¨üáß Answer:** To avoid **perfect multicollinearity**. If we have "Is_Male" and "Is_Female", they are perfectly correlated (if one is 1, the other is 0). This confuses linear models.
*   **üá∑üá∫ –û—Ç–≤–µ—Ç:** –ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å **–∏–¥–µ–∞–ª—å–Ω–æ–π –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏**. –ï—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å "Is_Male" –∏ "Is_Female", –æ–Ω–∏ –∏–¥–µ–∞–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—Ç (–µ—Å–ª–∏ –æ–¥–∏–Ω 1, –¥—Ä—É–≥–æ–π 0). –≠—Ç–æ –ø—É—Ç–∞–µ—Ç –ª–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏.

### Q2: Why is Logistic Regression better than KNN here?
### –í2: –ü–æ—á–µ–º—É –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –ª—É—á—à–µ, —á–µ–º KNN –∑–¥–µ—Å—å?
*   **üá¨üáß Answer:**
    1.  **Interpretability:** We can see which features increase income (positive coefficients).
    2.  **Scaling:** KNN fails without scaling; Logistic Regression is more robust (though scaling still helps).
    3.  **Speed:** KNN is slow on large datasets like 'Adult'.
*   **üá∑üá∫ –û—Ç–≤–µ—Ç:**
    1.  **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å:** –ú—ã –≤–∏–¥–∏–º, –∫–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–≤—ã—à–∞—é—Ç –¥–æ—Ö–æ–¥ (–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã).
    2.  **–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ:** KNN –ª–æ–º–∞–µ—Ç—Å—è –±–µ–∑ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è; –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –±–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤–∞ (—Ö–æ—Ç—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ —Ä–∞–≤–Ω–æ –ø–æ–ª–µ–∑–Ω–æ).
    3.  **–°–∫–æ—Ä–æ—Å—Ç—å:** KNN –º–µ–¥–ª–µ–Ω–Ω—ã–π –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö, —Ç–∞–∫–∏—Ö –∫–∞–∫ 'Adult'.

---

## üìê Math Intuition / –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ç—É–∏—Ü–∏—è

### Sigmoid Function (Logistic Regression)
$$ P(y=1) = \frac{1}{1 + e^{-z}} $$
*   **üá¨üáß EN:** It squashes any number (z) into a probability between 0 and 1.
*   **üá∑üá∫ RU:** –û–Ω–∞ —Å–∂–∏–º–∞–µ—Ç –ª—é–±–æ–µ —á–∏—Å–ª–æ (z) –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç 0 –¥–æ 1.
