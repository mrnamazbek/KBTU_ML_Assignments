{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Assignment 5: Adult Income Prediction \ud83d\udcb5\ud83d\udcca\n",
                "\n",
                "## \ud83d\udcda Learning Objectives\n",
                "- Perform data cleaning and preprocessing (handling missing values, encoding).\n",
                "- Visualize data distributions.\n",
                "- Train and compare **Logistic Regression** and **K-Nearest Neighbors (KNN)** classifiers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 1: Data Loading and Basic Inspection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q1\n",
                "Load the `adult` dataset (version 2) from OpenML. Display its shape, list the feature names, and identify the target variable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.datasets import fetch_openml # Import fetch_openml / \u0418\u043c\u043f\u043e\u0440\u0442 fetch_openml\n",
                "import pandas as pd # Data manipulation / \u0420\u0430\u0431\u043e\u0442\u0430 \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438\n",
                "import numpy as np # Numerical operations / \u0427\u0438\u0441\u043b\u043e\u0432\u044b\u0435 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438\n",
                "import matplotlib.pyplot as plt # Plotting / \u0413\u0440\u0430\u0444\u0438\u043a\u0438\n",
                "import seaborn as sns # Advanced plotting / \u041f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0435 \u0433\u0440\u0430\u0444\u0438\u043a\u0438\n",
                "\n",
                "# Fetch dataset\n",
                "adult = fetch_openml(name='adult', version=2, as_frame=True, parser='auto') # Fetch Adult dataset / \u0417\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 Adult\n",
                "df = adult.frame # Convert to DataFrame / \u041a\u043e\u043d\u0432\u0435\u0440\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0432 DataFrame\n",
                "\n",
                "print(\"Shape:\", df.shape)\n",
                "print(\"Features:\", df.columns.tolist())\n",
                "print(\"Target Variable:\", 'class' if 'class' in df.columns else 'income')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q2\n",
                "Display the non-null count and data type for each feature."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info() # Check data info / \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u0442\u044c \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u043e \u0434\u0430\u043d\u043d\u044b\u0445\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 2: Descriptive Statistics"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q3\n",
                "Generate summary statistics for both numerical and categorical columns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Numerical Summary ---\")\n",
                "display(df.describe()) # Summary statistics / \u041e\u043f\u0438\u0441\u0430\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\u0430\n",
                "\n",
                "print(\"\\n--- Categorical Summary ---\")\n",
                "display(df.describe(include=['object', 'category']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q4\n",
                "List all categorical columns and their unique values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cat_cols = df.select_dtypes(include=['object', 'category']).columns # Select columns by type / \u0412\u044b\u0431\u0440\u0430\u0442\u044c \u043a\u043e\u043b\u043e\u043d\u043a\u0438 \u043f\u043e \u0442\u0438\u043f\u0443\n",
                "for col in cat_cols:\n",
                "    print(f\"\\nColumn: {col}\")\n",
                "    print(df[col].unique())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q5\n",
                "Check for missing values in the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(df.isnull().sum()) # Count missing values / \u041f\u043e\u0434\u0441\u0447\u0438\u0442\u0430\u0442\u044c \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q5.1\n",
                "Handle missing values:\n",
                "1. Calculate the ratio of missing values for the dataset.\n",
                "2. If the ratio is < 20%, drop rows with missing values.\n",
                "3. If the ratio is >= 20%, impute missing values (median for numerical, mode for categorical)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "total_cells = np.product(df.shape)\n",
                "missing_cells = df.isnull().sum().sum() # Count missing values / \u041f\u043e\u0434\u0441\u0447\u0438\u0442\u0430\u0442\u044c \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\n",
                "ratio = missing_cells / total_cells\n",
                "\n",
                "print(f\"Missing Ratio: {ratio:.4f}\")\n",
                "\n",
                "if ratio < 0.20:\n",
                "    print(\"Ratio < 20%. Dropping rows with missing values...\")\n",
                "    df_clean = df.dropna() # Drop rows with missing values / \u0423\u0434\u0430\u043b\u0438\u0442\u044c \u0441\u0442\u0440\u043e\u043a\u0438 \u0441 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u043c\u0438\n",
                "else:\n",
                "    print(\"Ratio >= 20%. Imputing values...\")\n",
                "    # Simple imputation logic (for demonstration)\n",
                "    df_clean = df.copy()\n",
                "    for col in df_clean.columns:\n",
                "        if df_clean[col].dtype in [np.float64, np.int64]:\n",
                "            df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
                "        else:\n",
                "            df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
                "\n",
                "print(\"New Shape:\", df_clean.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 3: Visualization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q6\n",
                "Plot histograms for all numerical columns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_clean.hist(figsize=(12, 10), bins=20, edgecolor='black') # Plot histograms / \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u0433\u0438\u0441\u0442\u043e\u0433\u0440\u0430\u043c\u043c\u044b\n",
                "plt.suptitle('Histograms of Numerical Columns', fontsize=16)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q7\n",
                "Plot bar charts showing the frequency of each category for all categorical features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cat_cols = df_clean.select_dtypes(include=['object', 'category']).columns\n",
                "\n",
                "plt.figure(figsize=(16, 20))\n",
                "for i, col in enumerate(cat_cols, 1):\n",
                "    plt.subplot(5, 3, i)\n",
                "    sns.countplot(y=col, data=df_clean, order=df_clean[col].value_counts().index) # Plot category counts / \u0413\u0440\u0430\u0444\u0438\u043a \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0439\n",
                "    plt.title(col)\n",
                "    plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 4: Preprocessing and Modeling"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q8\n",
                "Assign the feature columns to `X` and the target column to `y`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Target is 'class' in OpenML adult dataset\n",
                "target_col = 'class'\n",
                "X = df_clean.drop(columns=[target_col])\n",
                "y = df_clean[target_col]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q9\n",
                "Apply One-Hot Encoding to the categorical features using `pandas.get_dummies()`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_encoded = pd.get_dummies(X, drop_first=True) # One-Hot Encoding / One-Hot \u041a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435\n",
                "print(\"Shape after encoding:\", X_encoded.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q10\n",
                "Split the dataset into training (80%) and testing (20%) sets using stratified sampling. Print the shapes of the resulting sets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split # Split data / \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, stratify=y, random_state=42) # Split data / \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435\n",
                "\n",
                "print(\"Train shape:\", X_train.shape)\n",
                "print(\"Test shape:\", X_test.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q11\n",
                "Train a Logistic Regression classifier on the training set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression # Initialize Logistic Regression / \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u041b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438\n",
                "\n",
                "# Increase max_iter to ensure convergence\n",
                "log_reg = LogisticRegression(max_iter=1000, random_state=42) # Initialize Logistic Regression / \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u041b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438\n",
                "log_reg.fit(X_train, y_train) # Train model / \u041e\u0431\u0443\u0447\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q12\n",
                "Report the accuracy score of the Logistic Regression model on the test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "score_log = log_reg.score(X_test, y_test) # Evaluate accuracy / \u041e\u0446\u0435\u043d\u0438\u0442\u044c \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c\n",
                "print(f\"Logistic Regression Accuracy: {score_log:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q13\n",
                "Train a K-Nearest Neighbors (KNN) classifier with `k=5`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.neighbors import KNeighborsClassifier # Initialize KNN / \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f KNN\n",
                "\n",
                "knn = KNeighborsClassifier(n_neighbors=5) # Initialize KNN / \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f KNN\n",
                "knn.fit(X_train, y_train) # Train KNN / \u041e\u0431\u0443\u0447\u0438\u0442\u044c KNN\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q14\n",
                "Report the accuracy score of the KNN model on the test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "score_knn = knn.score(X_test, y_test) # Evaluate KNN / \u041e\u0446\u0435\u043d\u0438\u0442\u044c KNN\n",
                "print(f\"KNN Accuracy: {score_knn:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q15\n",
                "**Question:** Explain the difference between Logistic Regression and K-Nearest Neighbors (KNN) in two sentences.\n",
                "\n",
                "**Answer:**\n",
                "**Logistic Regression** is a parametric linear model that learns a specific boundary (formula) to separate classes, making it fast and interpretable. **KNN** is a non-parametric instance-based learner that memorizes the training data and makes predictions based on local similarity, which can be computationally expensive but captures complex non-linear patterns."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}