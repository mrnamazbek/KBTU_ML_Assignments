{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Assignment 5: Adult Income Prediction ðŸ’µðŸ“Š\n",
                "\n",
                "## ðŸ“š Learning Objectives\n",
                "- Perform data cleaning and preprocessing (handling missing values, encoding).\n",
                "- Visualize data distributions.\n",
                "- Train and compare **Logistic Regression** and **K-Nearest Neighbors (KNN)** classifiers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 1: Data Loading and Basic Inspection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q1\n",
                "Load the `adult` dataset (version 2) from OpenML. Display its shape, list the feature names, and identify the target variable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.datasets import fetch_openml\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Fetch dataset\n",
                "adult = fetch_openml(name='adult', version=2, as_frame=True, parser='auto')\n",
                "df = adult.frame\n",
                "\n",
                "print(\"Shape:\", df.shape)\n",
                "print(\"Features:\", df.columns.tolist())\n",
                "print(\"Target Variable:\", 'class' if 'class' in df.columns else 'income')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q2\n",
                "Display the non-null count and data type for each feature."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 2: Descriptive Statistics"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q3\n",
                "Generate summary statistics for both numerical and categorical columns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Numerical Summary ---\")\n",
                "display(df.describe())\n",
                "\n",
                "print(\"\\n--- Categorical Summary ---\")\n",
                "display(df.describe(include=['object', 'category']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q4\n",
                "List all categorical columns and their unique values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
                "for col in cat_cols:\n",
                "    print(f\"\\nColumn: {col}\")\n",
                "    print(df[col].unique())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q5\n",
                "Check for missing values in the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(df.isnull().sum())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q5.1\n",
                "Handle missing values:\n",
                "1. Calculate the ratio of missing values for the dataset.\n",
                "2. If the ratio is < 20%, drop rows with missing values.\n",
                "3. If the ratio is >= 20%, impute missing values (median for numerical, mode for categorical)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "total_cells = np.product(df.shape)\n",
                "missing_cells = df.isnull().sum().sum()\n",
                "ratio = missing_cells / total_cells\n",
                "\n",
                "print(f\"Missing Ratio: {ratio:.4f}\")\n",
                "\n",
                "if ratio < 0.20:\n",
                "    print(\"Ratio < 20%. Dropping rows with missing values...\")\n",
                "    df_clean = df.dropna()\n",
                "else:\n",
                "    print(\"Ratio >= 20%. Imputing values...\")\n",
                "    # Simple imputation logic (for demonstration)\n",
                "    df_clean = df.copy()\n",
                "    for col in df_clean.columns:\n",
                "        if df_clean[col].dtype in [np.float64, np.int64]:\n",
                "            df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
                "        else:\n",
                "            df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
                "\n",
                "print(\"New Shape:\", df_clean.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 3: Visualization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q6\n",
                "Plot histograms for all numerical columns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_clean.hist(figsize=(12, 10), bins=20, edgecolor='black')\n",
                "plt.suptitle('Histograms of Numerical Columns', fontsize=16)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q7\n",
                "Plot bar charts showing the frequency of each category for all categorical features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cat_cols = df_clean.select_dtypes(include=['object', 'category']).columns\n",
                "\n",
                "plt.figure(figsize=(16, 20))\n",
                "for i, col in enumerate(cat_cols, 1):\n",
                "    plt.subplot(5, 3, i)\n",
                "    sns.countplot(y=col, data=df_clean, order=df_clean[col].value_counts().index)\n",
                "    plt.title(col)\n",
                "    plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 4: Preprocessing and Modeling"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q8\n",
                "Assign the feature columns to `X` and the target column to `y`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Target is 'class' in OpenML adult dataset\n",
                "target_col = 'class'\n",
                "X = df_clean.drop(columns=[target_col])\n",
                "y = df_clean[target_col]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q9\n",
                "Apply One-Hot Encoding to the categorical features using `pandas.get_dummies()`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_encoded = pd.get_dummies(X, drop_first=True)\n",
                "print(\"Shape after encoding:\", X_encoded.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q10\n",
                "Split the dataset into training (80%) and testing (20%) sets using stratified sampling. Print the shapes of the resulting sets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, stratify=y, random_state=42)\n",
                "\n",
                "print(\"Train shape:\", X_train.shape)\n",
                "print(\"Test shape:\", X_test.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q11\n",
                "Train a Logistic Regression classifier on the training set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "\n",
                "# Increase max_iter to ensure convergence\n",
                "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
                "log_reg.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q12\n",
                "Report the accuracy score of the Logistic Regression model on the test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "score_log = log_reg.score(X_test, y_test)\n",
                "print(f\"Logistic Regression Accuracy: {score_log:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q13\n",
                "Train a K-Nearest Neighbors (KNN) classifier with `k=5`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "\n",
                "knn = KNeighborsClassifier(n_neighbors=5)\n",
                "knn.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q14\n",
                "Report the accuracy score of the KNN model on the test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "score_knn = knn.score(X_test, y_test)\n",
                "print(f\"KNN Accuracy: {score_knn:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q15\n",
                "**Question:** Explain the difference between Logistic Regression and K-Nearest Neighbors (KNN) in two sentences.\n",
                "\n",
                "**Answer:**\n",
                "**Logistic Regression** is a parametric linear model that learns a specific boundary (formula) to separate classes, making it fast and interpretable. **KNN** is a non-parametric instance-based learner that memorizes the training data and makes predictions based on local similarity, which can be computationally expensive but captures complex non-linear patterns."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}